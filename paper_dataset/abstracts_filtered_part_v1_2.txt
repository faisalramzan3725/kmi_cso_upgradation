Progress is reported in the design and analysis of spread-spectrum packet radio_networks for the factory of the future This progress includes the accurate analysis of the probability of packet success in a direct-sequence spread-spectrum communication channel and analytical_results on the transient behavior of packet radio_networks The first use of these networks will be to provide communications between a transport system controller and a fleet of autonomous guided vehicles
Manufacturing decision making with FACTOR
The FACTOR system is designed to support the effective management of the capacity of manufacturing organization This philosophy is best described as total capacity management TCM The TCM fundamental principle suggests that through a thorough understanding of a system s capacity and the ability to control that capacity a manufacturing system can profitably and predictably deliver quality products to its customers This tutorial covers the basic concepts of FACTOR FACTOR has been applied to engineering_design scheduling and planning problems within many manufacturing organizations Topics covered include the FACTOR modeling constructs integration with existing production data the use of FACTOR for schedule creation and adjustment FACTOR AIM and new enhancements to the products
Learning with Technology Using Discussion Forums to Augment a Traditional-Style Class
There is considerable evidence that using technology as an instructional tool improves student_learning and educational outcomes Hanna de Nooy 2003 In developing countries pre-university education focuses on memorization although meting the mission of AUST requires students to manage technology and to think more independently This study examines the impact of incorporating a discussion forum on the achievement of university students enrolled in a distance_education course educational_technology Department at Ajman University of Science and Technology AUST United Arab Emirates The study was conducted with 34 students divided into two sections one a treatment group and one a control group Both sections were exposed to the same teaching techniques covering the same course material on distance_education Four weeks after the course had commenced they were given the same teacher constructed test However after the first test the treated group was exposed to the use of a world_wide_web WWW interactive discussion forum At the end of the semester-long treatment period a final test was given to both groups and student scores were analyzed for any statistically significant difference Questionnaires and interviews were also conducted to see if students had enjoyed the experience The results of the study indicated that students in both groups showed learning improvement over the course of one semester but discussion forums had an obvious impact on student achievement and attitude in distance_learning educational_technology course
CCHMM_PROF a HMM-based Coiled-Coil Predictor with Evolutionary Information
Motivation The widespread coiled-coil structural motif in proteins is known to mediate a variety of biological interactions Recognizing a coiled-coil containing sequence and locating its coiled-coil domains are key steps towards the determination of the protein structure and function Different tools are available for predicting coiled-coil domains in protein sequences including those based on positionspecific score matrices and machine_learning_methods Results In this article we introduce a hidden_markov_model CCHMM_PROF that exploits the information contained in multiple sequence alignments profiles to predict coiled-coil regions The new method discriminates coiled-coil sequences with an accuracy of 97 and achieves a true positive rate of 79 with only 1 of false positives Furthermore when predicting the location of coiled-coil segments in protein sequences the method reaches an accuracy of 80 at the residue level and a best per-segment and perprotein efficiency of 81 and 80 respectively The results indicate that CCHMM_PROF outperforms all the existing tools and can be adopted for large-scale genome annotation Availability The dataset is available at http www biocomp unibo it lisa coiled-coils The predictor is freely available at http gpcr biocomp unibo it cgi predictors cchmmprof pred_cchmmprof cgi Contact piero biocomp unibo it
Performance of local area network_protocols for hard_real-time_applications
Simulation experiments show that the token ring protocol gave a lower average message delay at low transfer rates but the token bus protocol gave a better overall performance for applications where only average delay is of interest On the other hand in hard_real-time_systems the criterion of importance is not the average message delay but the maximum message delay and the ability to meet deadlines Slotted ring in this case is a much better protocol than the others because of its low maximum message delay and more predictable message delay Because of this and because the average performance of the slotted ring remains good as the size or the transfer rate of the network increases the slotted ring protocol is preferred over the token ring and token bus protocols for hard_real-time_systems
A simple algorithm for decomposing convex structuring_elements
A finite subset of Z sup 2 is called a structuring_element The paper presents a new and simple algorithm for decomposing a convex structuring_element as a sequence of Minkowski additions of a minimum number of subsets of the elementary square i e the 3 spl times 3 square centered at the origin Besides its simplicity the advantage of this algorithm over some known algorithms is that it generates a sequence of non necessarily convex subsets which means subsets with smaller cardinality and consequently faster implementation of the corresponding dilations and erosions The algorithm is based on algebraic and geometrical properties of Minkowski additions Theoretical analysis of correctness and computational_time complexity are also presented
A BIST pattern generator design for near-perfect fault_coverage
A new design methodology for a pattern generator is proposed formulated in the context of on-chip BIST The design methodology is circuit-specific and uses synthesis techniques to design BIST generators The pattern generator consists of two components a pseudorandom pattern generator like an LFSR or preferably a GLFSR and a combinational logic to map the outputs of the pseudorandom pattern generator This combinational logic is synthesized to produce a given set of target patterns by mapping the outputs of the pseudorandom pattern generator It is shown that for a particular CUT an area-efficient combinational logic block can be designed synthesized to achieve 100 or almost 100 percent single stuck-at fault_coverage using a small number of test the This method is significantly different from weighted pattern generation and can guarantee testing of all hard-to-detect faults without expensive test point insertion Experimental results on common benchmark netlists demonstrate that the fault_coverage of the proposed pattern generator is significantly higher compared to conventional pattern generation techniques The design technique for the logic mapper is unique and can be used effectively to improve existing pattern generators for combinational logic and scan-based BIST structures
MODEL OF CARDIAC TISSUE AS A CONDUCTIVE SYSTEM WITH INTERACTING PACEMAKERS AND REFRACTORY TIME
The model of the cardiac tissue as a conductive system with two interacting pacemakers and a refractory time is proposed In the parametric_space of the model the phase locking areas are investigated in detail The obtained results make possible to predict the behavior of excitable systems with two pacemakers depending on the type and intensity of their interaction and the initial phase Comparison of the described phenomena with intrinsic pathologies of cardiac rhythms is given
The Systolic Pixel A Visible Surface Algorithm for VLSI
Abstract R N R N The Systolic Pixel or Spixel is a novel_architecture for an intelligent pixel-based graphics database for geometric-solid models An algorithm is described which performs visible surface calculations for any complexity of coloured 3-dimensional 3-D surface and which structures geometric-solid model data in a natural way The algorithm architecture of the spixel features a simple set of priority rules acting upon data in nearest neighbour locations and a simple set of movement rules of data to nearest neighbour locations The spixel is constructed out of identical functional units These features are attractive for an implementation of the algorithm in Very Large Scale Integration VLSI
Generating Case Markers in machine_translation
We study the use of rich syntax-based statistical_models for generating grammatical case for the purpose of machine_translation from a language which does not indicate case explicitly English to a language with a rich system of surface case markers Japanese We propose an extension of n-best re-ranking as a method of integrating such models into a statistical MT system and show that this method substantially outperforms standard n-best re-ranking Our best performing model achieves a statistically significant improvement over the baseline MT system according to the BLEU metric human_evaluation also confirms the results
Soft-limiter receivers for coded DS DPSK systems
The performance of a soft-limiter metric and a quantized soft-limiter metric is evaluated for coded DS DPSK direct_sequence differential_phase_shift_keying in the presence of worst case pulse jamming and background_noise The metrics are easy to implement and do not require jammer state information Instead they rely on the use of receiver thresholds which must be adjusted according to the code rate and the received bit-energy-to-background-noise ratio The performance of the metrics is evaluated by using the cutoff rate criterion and a number of specific convolutional and block_codes It is shown that the metrics can offer a significant soft-decision_decoding_gain and can perform to within 0 5-1 5 dB of the maximum-likelihood soft-decision metric with perfect jammer state information
Technology Dependence In function_point_analysis A Case Study And Critical Review
Because function_point_analysis FPA has now been in use for a decade and in spite of its increasing popularity has met with some recent criticisms it is time to review how appropriate it still is for today s technologies A critical review of the FPA approach examines in particular the pioneering and continuing work of Albrecht and more recent work by Symons Technological dependencies in FPA-type metrics are identified and a general model for deriving a new FPA-type metric for a new software technology is given A model for the calibration of FPA-type metrics for new technologies in terms of a reference technology is also presented Such calibration is essential for comparative productivity studies The role of module estimation in exposing parts of the anatomy of the FPA approach is investigated The derivation and calibration models are applied to a significant case study in which a new FPA-type metric suited to a particular software_development technology is derived calibrated and compared with other published versions of FPA metrics
Pruning recurrent_neural_networks for improved generalization performance
The experimental results in this paper demonstrate that a simple pruning retraining method effectively improves the generalization performance of recurrent_neural_networks trained to recognize regular_languages The technique also permits the extraction of symbolic knowledge in the form of deterministic finite-state automata DFA which are more consistent with the rules to be learned Weight decay has also been shown to improve a network s generalization performance Simulations with two small DFA spl les 10 states and a large finite-memory machine 64 states demonstrate that the performance improvement due to pruning retraining is generally superior to the improvement due to training with weight decay In addition there is no need to guess a good decay rate
Adaptive design of digital filters
In this paper we present a novel technique for the design of FIR and iir_digital_filters The design approach begins with the specification of a discrete set of arbitrary magnitude and phase characteristics which describe a desired filter response These frequency_domain characteristics are used to create an ideal pseudo-filter whose impulse_response is unknown and possibly non-causal but whose input output characteristics can be determined for a finite sum of sinusoids Time-domain techniques common to adaptive_system identification are then used to identify a realizable FIR or IIR digital filter which best matches the pseudo-filter The advantages of this method include the ability to specify response at arbitrarily-spaced frequencies to use arbitrary cost weighting and to apply possibly non-linear constraints to the range of the filter_coefficients
Experimental Examination in simulated interactive situation between people and mobile_robot with preliminary-announcement and indication function of upcoming operation
This paper presents the result of the experimental examination by passing each other and positional prediction in simulated interactive situation between people and mobile_robot We have developed four prototype robots based on four proposed methods for preliminarily announcing and indicating to people the speed and direction of upcoming movement of mobile_robot moving on two-dimensional plane We observed significant difference between when there was a preliminary-announcement and indication PAI function and when there was not even in each experiment Therefore the effect of preliminary-announcement and indication of upcoming operation was declared In addition the feature and effective usage of each type of preliminary-announcement and indication method were clarified That is the method of announcing state of operation just after the present is effective when a person has to judge to which direction he should get on immediately due to the feature that simple information can be quickly transmitted The method of indicating operations from the present to some future time continuously is effective when a person wants to avoid contact or collision surely and correctly owing to the feature that complicated information can be accurately transmitted We would like to verify the result in various conditions such as the case that traffic lines are obliquely crossed
opportunistic_beamforming over rayleigh_channels with Partial Side Information
In recent years diversity techniques have evolved into highly attractive technology for wireless_communications in different forms For instance the channel fluctuations of the users in a network are exploited as multiuser_diversity by scheduling the user with the best signal-to-noise_ratio SNR When fading is slow beamforming at a multiple_antenna transmitter is used to induce artificial channel fluctuations to ensure multiuser_diversity in the network Such a beamforming scheme is called opportunistic_beamforming since the transmitter uses random beamforming to artificially induce opportunism in the network 1 Opportunism requires a large number of users in the system in order to reach the performance of the true beamforming that uses perfect_channel_state_information CSI In this paper we investigate the benefit of having partial_csi at an opportunistic transmitter In the investigation we focus on the maximum normalized SNR scheduling where user s feedback consists of SNR relative to its channel gain We show that opportunism can be beneficially used to increase the average throughput of the system Simulations support the analytical average throughput results obtained as the amount of CSI and the number of users vary
An ilp_formulation for system level throughput and power optimization in multiprocessor SoC architectures
System-level low_power scheduling techniques are required for optimizing the performance and power of embedded_applications that are mapped to multiprocessor_system-on-Chip SoC architectures In this paper we present an integer linear programming ilp_formulation that combines loop transformations pipelining and unrolling and system-level low_power optimization_techniques dynamic voltage scaling DVS and power_management DPM to minimize the power consumption while satisfying the period and deadline constraints of the application We also present three modifications that relax one or more constraints in the optimal formulation in order to obtain smaller run times We present experimental analysis by applying the formulations on an MPEG decoder algorithm All results are compared against two existing techniques Our formulations result in large system-level power reductions max 48 2 min 15 92 avg 31 9 The modified ilp_formulations result in exponential decrease in runtimes and a corresponding linear degradation in the result quality
Enhancement of semantics in CBIR
Although much research has been done in the area of content_based_image_retrieval CBIR little progress has been made to fully implement an engine solely based on the search of image content This paper examines one of the basic problems in pattern_recognition which highlights the difficulty in the area of content understanding in CBIR i e the inability of current systems to fully incorporate low level features of image such as intensity colour texture shape and spatial constraints characteristics with the high level features such as semantic content To further the development of content based image_processing semantic algorithms should be combined with low level features and be used to process the image objects
MASISH a database for gene expression in maize seeds
Grass seeds are complex organs composed by multiple tissues and cell types which develop coordinately to produce a viable embryo The identification of genes involved in seed development is of great interest but systematic spatial analyses of gene expression on maize seeds at the cell level have not yet been performed MASISH is an online database holding information for gene expression spatial patterns in maize seeds based on in situ hybridization experiments The web-based query interface allows the execution of gene queries and provides hybridization images published references and information of the analyzed genes Availability http masish uab cat Contact cvsgmp cid csic es The maize kernel is classified botanically as a caryopsis In consequence it is a fruit composed by one seed and the remnants of the seed coats and nucellus and is permanently enclosed in the pericarp The endosperm occupies most of the seed and is basically a storage organ that accumulates starch and proteins The aleurone layer is part of the endosperm and consists in a continuous layer of large cubical cells which accumulate protein and lipid granules and surrounds most of the endosperm In the area of the pedicel which connects the seed to the mother plant the cells adopt a special morphology typical of transfer cells and form the basal transfer cell layer The embryo consists of an embryonic axis and a single cotyledon which is called the scutellum The embryo axis is formed by the plumule covered by the coleoptile and the radicle covered by coleorhiza All these organs are almost completely surrounded by the scutellum an organ whose major function is to accumulate nutrient reserves mainly lipids and proteins A single layer of cells directly in contact with the endosperm which is called the scutellar epithelium is important in the digestion and transport of the nutrients from the endosperm to the embryo axis during germination Both endosperm and embryo derive from the fusion of gametes but while the embryo is derived from the fertilized egg triploid endosperm is derived from fertilized polar nuclei Surrounding the endosperm and embryo lays the pericarp a protective organ derived from maternal tissues more information at http masish uab cat masish images maizeseedanatomy pdf Full genome sequencing allows the identification of the complete catalog of genes in a species However the roles of a high proportion of these genes remain unknown The description of
Unified Blind Method for Multi-image_super-resolution and Single Multi-Image Blur Deconvolution
This paper presents for the first time a unified blind method for multi-image_super-resolution MISR or SR single-image blur deconvolution SIBD and multi-image blur deconvolution MIBD of low-resolution LR images degraded by linear space-invariant LSI blur aliasing and additive_white_gaussian_noise AWGN The proposed approach is based on alternating minimization AM of a new cost function with respect to the unknown high-resolution HR image and blurs The regularization term for the HR image is based upon the Huber-markov_random_field HMRF model which is a type of variational integral that exploits the piecewise smooth nature of the HR image The blur estimation process is supported by an edge-emphasizing smoothing operation which improves the quality of blur estimates by enhancing strong soft edges toward step edges while filtering out weak structures The parameters are updated gradually so that the number of salient edges used for blur estimation increases at each iteration For better performance the blur estimation is done in the filter domain rather than the pixel_domain i e using the gradients of the LR and HR images The regularization term for the blur is Gaussian L2 norm which allows for fast noniterative optimization in the frequency_domain We accelerate the processing time of SR reconstruction by separating the upsampling and registration processes from the optimization procedure Simulation results on both synthetic and real-life images from a novel computational imager confirm the robustness and effectiveness of the proposed method
Synthesis of multi-qudit hybrid and d-valued quantum logic circuits by decomposition
Recent research in generalizing quantum computation from 2-valued qudits to d-valued qudits has shown practical advantages for scaling up a quantum computer A further generalization leads to quantum computing with hybrid qudits where two or more qudits have different finite dimensions Advantages of hybrid and d-valued gates circuits and their physical realizations have been studied in detail by Muthukrishnan and Stroud Multi-valued logic_gates for quantum computation Phys Rev A 62 2000 052309 10 Daboul et al quantum_gates on hybrid qudits J Phys A Math Gen 36 2003 2525-2536 5 and Bartlett et al Quantum encodings in spin systems and harmonic oscillators Phys Rev A 65 2002 052316 17 In both cases a quantum computation is performed when a unitary evolution operator acting as a quantum logic_gate transforms the state of qudits in a quantum system Unitary operators can be represented by square unitary matrices If the system consists of a single qudit then Tilma et al Generalized Euler angle parameterization for SU N J Phys A Math Gen 35 2002 10467-10501 15 have shown that the unitary evolution matrix gate can be synthesized in terms of its Euler angle parametrization However if the quantum system consists of multiple qudits then a gate may be synthesized by matrix decomposition techniques such as qr_factorization and the cosine-sine decomposition CSD In this article we present a CSD based synthesis method for n qudit hybrid quantum_gates and as a consequence derive a CSD based synthesis method for n qudit gates where all the qudits have the same dimension
Point location in zones of k -flats in arrangements
Abstract Let A H be the arrangement of a set H of n hyperplanes in d -space A k -flat is a k -dimensional affine subspace of d -space The zone of a k -flat f with respect to H is the set of all faces in A H that intersect f this paper we study some problems on zones of k -flats Our most important result is a data structure for point location in the zone of a k -flat This structure uses O n d 2 e n k e preprocessing time and space and has a query time of O log 2 n We also show how to test efficiently whether two flats are visible from each other with respect to a set of hyperplanes Then point location in m faces in arrangements is studied Our data structure for this problem has size O n d 2 e m d 2 d and the query time is O log 2 n
Dynamic optimal battery array management in high energy density fuel cell battery hybrid power source
The goal of this paper is to address the problem of dynamic optimal battery array management to extend the life of battery array used in the hybrid power source Unlike previous efforts which mainly solve the problem using the off-line optimization our design addresses the problem using the idea of feedback The proposed approach can handle the possible dynamic uncertainty of the hybrid power source introduced by battery failure or insert of a new battery The detailed battery model and the converter model are derived to facilitate development of dynamic optimal management algorithm The other goal of this paper is to call possible attention of the control community in potential contribution for newest smart_grid_technology
Expectation-maximization approach to Boolean factor analysis
Methods for hidden structure of high-dimensional binary data discovery are one of the most important challenges facing machine_learning community researchers There are many approaches in literature that try to solve this hitherto rather ill-defined task In the present study we propose a most general generative_model of binary data for Boolean factor analysis and introduce new Expectation-Maximization Boolean Factor Analysis algorithm which maximizes likelihood of Boolean Factor Analysis solution Using the so-called bars problem benchmark we compare efficiencies of Expectation-Maximization Boolean Factor Analysis algorithm with Dendritic Inhibition neural_network Then we discuss advantages and disadvantages of both approaches as regards results quality and methods efficiency
Bridgeless SEPIC PFC Rectifier With Reduced Components and Conduction Losses
In this paper a new bridgeless single-ended primary inductance converter power-factor-correction rectifier is introduced The proposed circuit provides lower conduction losses with reduced components simultaneously In conventional PFC converters continuous-conduction-mode boost converter a voltage loop and a current loop are required for PFC In the proposed converter the control circuit is simplified and no current loop is required while the converter operates in discontinuous conduction mode Theoretical analysis and simulation results are provided to explain circuit operation A prototype of the proposed converter is realized and the results are presented The measured efficiency shows 1 improvement in comparison to conventional SEPIC rectifier
Spurious-Free Dynamic Range of a Uniform Quantizer
Quantization plays an important role in many systems where analog-to-digital conversion and or digital-to-analog conversion take place If the quantization error is correlated with the input signal then the spectrum of the quantization error will contain spurious peaks Although analytical formulas describing this effect exist numerical evaluation can take much effort This brief provides approximations for the spurious-free dynamic range SFDR of a uniform quantizer with a single sinusoidal input with and without additive_gaussian_noise It is shown that the SFDR increases by approximately 8 dB bit in case there is no noise Generalizing this result to multitone inputs results in an additional 2 dB bit per additional tone additive_gaussian_noise decorrelates the sinusoid s and the quantization error which results in a dramatic increase in SFDR
Binding time in distributed shared_memory_architectures
The paper revisits three distributed shared_memory DSM architectures to clarify them with their binding times for new addresses at the local memory page fault time node miss time and cache_miss time The DSM architectures which have different binding times arrange data in different ways with different overheads at an event of reference Since a large number of cache_misses can occur in a large relative to the cache_size working set binding at the page fault time alone cannot efficiently utilize locality of reference at the local memory In a small working set most of the addresses bound to the local memory at a node miss time are not effective due to the low cache_miss rate The paper shows that binding at the cache_miss time can improve system performance
Reasoning about Human Intention Change for Individualized Runtime Software Service Evolution
While software_evolution has been studied extensively in software_engineering few of these efforts have involved a systematic exploration of human epistemological attitudes such as human desire and intention as the driving force of software service evolution Our work proposes a theoretical framework to monitor and reason about human intention and its changes which in turn can be used to determine how software and services should evolve to be individualized and better serve each user Extending the Situ framework we explore the service satisfiability_problem through sub-world coverage following kripke_semantics which enjoys wide application in AI and other fields related to human epistemic reasoning
A comparative assessment of web_accessibility and technical standards conformance in four EU states
The Internet is playing a progressively more important part in our day to day life through its power of making information universally available people_with_disabilities have particular opportunities to benefit Using the Internet in conjunction with dedicated assistive_technologies tasks that were very difficult if not impossible to achieve for people with various types of disability can now be made fully accessible at least in principle However in practice many online resources and services are still poorly accessible to those with disability due to unsatisfactory web_content design N N Design of accessible web_content is codified in standards and guidelines of the world_wide_web Consortium W3C Conformance with W3C s web_content Accessibility Guidelines 1 0 WCAG and or similar derivative guidelines is now the subject of considerable activity both legal and technical in many different jurisdictions N N This paper presents results of a comparative survey of web_accessibility guidelines and HTML standards conformance for samples of Web sites drawn from Ireland the United Kingdom France and Germany It also gives some recommendations on how to improve the accessibility level of web_content N N A particular conclusion of the study is that the general level of web_accessibility guidelines and HTML standards conformance in all of the samples studied is very poor and that the pattern of failure is strikingly consistent in the four samples Although considerable efforts are being made to promote web_accessibility for users_with_disabilities this is certainly not yet manifesting itself in improving web_accessibility and HTML validity
Evolution of a four wheeled active_suspension rover with minimal actuation for rough terrain mobility
In this paper we deduce the evolution of a four wheeled active_suspension rover from a five wheeled passive_suspension rover The aim of this paper is to design a suspension mechanism which utilizes the advantages of both passive_suspension and active_suspension rover Both the design considered here are simpler than the existing suspension mechanisms in the sense that the number of links as wells as the number of joints have been significantly reduced without compromising the climbing capability of the rover We first analyze the kinematics of the five wheeled rover and its motion pattern while climbing an obstacle and try to deduce the same motion pattern and capability in the four wheeled rover Both the suspension mechanism consists of two planar closed kinematic_chains on each side of the rover We also deduce the control strategy for the active_suspension rover wherein only two actuators are used to control the internal configuration of the rover To the best of author s knowledge this is the minimum number of actuators required to control the internal configuration of a active_suspension while operating on a fully 3D rough terrain Extensive uneven terrain simulations are performed for both 5-wheeled and 4-wheeled rover and a comparative analysis has been done on maximum coefficient of friction and torque requirements
data_fusion_algorithms for network_anomaly_detection classification and evaluation
In this paper the problem of discovering anomalies in a large-scale network based on the data_fusion of heterogeneous monitors is considered We present a classification of anomaly_detection_algorithms based on data_fusion and motivated by this classification the operational principles and characteristics of two different representative approaches one based on the Demster-Shafer theory of evidence and one based on principal_component_analysis are described The detection effectiveness of these strategies are evaluated and compared under different attack scenarios based on both real data and simulations Our study and corresponding numerical_results revealed that in principle the conditions under which they operate efficiently are complementary and therefore could be used effectively in an integrated way to detect a wider range of attacks
A Method for Real-Time Identification of Malformed BGP Messages
The BGP routing system is one of the key component of today s Internet infrastructure responsible for carrying data traffic across different Autonomous Systems ASes Recently malformed BGP messages have become a threat to the operational community as they repeatedly cause BGP session resets until identified However the identification of the message itself is often difficult in large ISP networks In this paper we propose a novel method for real-time identification of these messages by using passively collects BGP messages Our method focuses on the frequency of observed attributes and values of prefixes advertised by each AS Based on our heuristics that common attributes are observed at similar time scale we periodically measure the usage frequency of attributes from BGP messages observed in real-time and mark attributes and values used by minority of the AS as suspicious We verify the efficiency of our method using BGP data obtained from operational networks
Link Characteristics Measuring in 2 4 GHz Body Area sensor_networks
With the increasing demands on the remote healthcare and the rich human-machine interacting body area sensor_network BASN has been attracting more and more attention In practice understanding the link performance and its dynamics in the emerging BASN applications is very important to design reliable real-time and energy-efficient protocols In this paper we study the link characteristics of body area sensor_network BASN through extensive experiments with very realistic configurations We evaluate the packet reception ratio RSSI LQI and movement intensity of body under indoor and outdoor environments all of which can provide direct insights to practical account
Implicit spatial inference with sparse local_features
This paper introduces a novel way to leverage the implicit geometry of sparse local_features e g SIFT operator for the purposes of object_detection and segmentation A two-class Bayesian scheme is used as a framework and the likelihood is derived from the real-valued classification of machine_learning algorithm Gentle AdaBoost whose output is transformed to a probabilistic_distribution using either of two models investigated Log-Sigmoid or Bi-Gaussian The main contribution is a novel scheme for the injection of prior contextual spatial information This occurs on a uniquely designed markov_random_field defined by Delaunay Tri- angulation of the feature points Our experiments show that this framework is useful for object_detection and segmentation and we achieve good mostly invariant results in these tasks
A geometrical framework for the determination of ambiguous directions in subspace methods
In signal_subspace parameter estimation techniques like MUSIC degradations may occur due to parasite peaks in the spectrum which may be connected to high sidelobes in the beam_pattern or to ambiguities themselves This paper studies the presence of ambiguities in an array of given planar geometry We propose a general framework for the analysis and thus we obtain a generalisation of results published by Lo and Marple 1992 and by Proukakis and Manikas see Proc ICASSP 94 vol 4 p 549-52 1994 for rank one and two ambiguities For rank k spl ges 3 ambiguities the study is restricted to linear_arrays for which we derive original and synthetic results We present a geometrical construction that is able to determine all the ambiguous directions which can appear for a given linear_array The method allows determination of any rank ambiguities and for each ambiguous direction set the rank of ambiguity is obtained The search is exhaustive Application of the method requires no assumption for the linear_array and is easy to implement An example is detailed for a non-uniform_linear_array
Nonrigid Intraoperative Cortical Surface_tracking Using game_theory
During neurosurgery nonrigid brain deformation prevents preoperatively acquired images from accurately depicting the intraoperative brain stereo_vision_systems can be used to track cortical surface deformation and update preoperative brain images in conjunction with a biomechanical model However these stereo systems are often plagued with calibration error which can corrupt the deformation estimation In order to decouple the effects of camera calibration and surface deformation a framework is needed which can solve for disparate and often competing variables game_theory which was developed specifically to handle decision making in this type of competitive environment has been applied to various fields from economics to biology In this paper we apply game_theory to cortical surface_tracking and use it to infer information about the physical processes of brain deformation and image_acquisition
A quality control mechanism for networked virtual_reality system with video capability
Introduction of motion video including live video into networked virtual_reality systems makes virtual_spaces more attractive To handle live video in networked virtual_reality systems based on VRML the scalability of networked virtual_reality systems becomes very important on the Internet where the performance of the network and the end systems varies dynamically We propose a new quality control mechanism suitable for networked virtual_reality systems with live video capability Our approach is to introduce the notion of the importance of presence IoP which represents the importance of objects in virtual_spaces According to IoP the degree of the deterioration of object presentation will be determined in case of the starvation of system resources
50th Anniversary Article The Evolution of Research on information_systems A Fiftieth-Year Survey of the Literature in management_science
The development of the information_systems IS literature inmanagement_science during the past 50 years reflects the inception growth and maturation of several different research streams The five research streams we identify incorporate different definitions of the managerial problems that relate to IS the alternate theoretical perspectives and different methodological paradigms to study them and the levels of the organization at which their primary results impact managerial practice Thedecision support and design science research stream studies the application of computers in decision support control and managerial decision making Thevalue of information research stream reflects relationships established based on economic analysis of information as a commodity in the management of the firm Thehuman-computer_systems_design research stream emphasizes the cognitive basis for effective systems_design TheIS organization and strategy research stream focuses the level of analysis on the locus of value of the IS investment instead of on the perceptions of a system or its user Theeconomics of information_systems and technology research stream emphasizes the application of theoretical perspectives and methods from analytical and empirical economics to managerial problems involving IS and information technologies IT Based on a discussion of these streams we evaluate the IS literature s core contributions to theoretical and managerial knowledge and make some predictions about the road that lies ahead for IS researchers
Transient signal_detection with neural_networks The Search for the desired_signal
Matched filtering has been one of the most powerful techniques employed for transient detection Here we will show that a dynamic neural_network outperforms the conventional approach When the artificial_neural_network ANN is trained with supervised_learning schemes there is a need to supply the desired_signal for all time although we are only interested in detecting the transient In this paper we also show the effects on the detection agreement of different strategies to construct the desired_signal The extension of the Bayes decision_rule 0 1 desired_signal optimal in static classification performs worse than desired_signals constructed by random noise or prediction during the background
Recursive construction and evolution of collaborative business_processes
Virtual Enterprises VEs bring together expertise and processes of different companies to react to a market opportunity N Here we propose a novel approach to support the collaborative construction and evolution of such VEs and their business_processes N comprising a model of the VE and a set of model construction rules and operators Our approach is based on the principles N of iterative elaboration devolved decision-making and situatedness and achieves flexibility by treating the processes of N work coordination and selection in a uniform manner We argue that certain assumptions behind existing approaches make them N unsuitable to the business practices we observed in the target business ecosystem We then show how the proposed approach N can underpin software support for informal business practices of collaborative process construction by manufacturing SMEs
Workspace of a six-revolute decoupled robot_manipulator
In this paper we study the working space of a six-revolute decoupled robot_manipulator A simple and direct method is presented to obtain the boundaries of the total and primary workspace The technique is based on finding the limit configurations of the general geometry positioning mechanism of the decoupled manipulator In order to do this we derive a fourth-order displacement equation in the first joint variable It is shown that the method only requires the simultaneous solution of two second-order nonlinear_equations
The rise and fall of an executive information_system a case study
The progress of an executive information_system project within a manufacturing organization over a period of 9 years is described The case study illustrates the importance of the interaction between the business environment the organizational environment and the perceptions and interpretations of events and facts by stakeholders on the success or failure of an information_system It shows the importance of context in the development and implementation of an executive information_system and the dynamic nature of the influence of social economic and technical factors The reasons for the initial success and the subsequent failure of the EIS within the company are explored from a contingency perspective
Adapting the eBlock Platform for Middle School STEM Projects Initial Platform usability_testing
The benefits of project-based learning_environments are well documented however setting up and maintaining these environments can be challenging due to the high cost and expertise associated with these platforms To alleviate some of these roadblocks the existing eBlock platform which is composed of fixed function building blocks targeted to enable nonexperts users to easily build a variety of interactive electronic_systems is expanded to incorporate newly defined integer-based building blocks to enable a wider range of project possibilities for middle school STEM projects We discuss various interface possibilities including initial usability experiments and summarize our overall experiences and observations in working with local middles school students utilizing the eBlock platform
Cooperative multi-antenna_relaying in heterogeneous_networks
In this paper we investigate the performance of heterogeneous_networks with multi-antenna cooperative_relays Specifically threshold-based maximum ratio combining MRC and selection_combining SC schemes are adopted for decoding at the relays and the end-to-end E2E error rate performance is analyzed by assuming a Nakagami channel_model numerical_results show that the deployment of multi-antennas can reduce the number of required relay_nodes and thus significantly reduce the system cost On the other hand the selection of optimal decoding threshold depends on the number of relay_nodes number of antennas as well as the average SNR value at the receiver It is also demonstrated that when the BER requirement is not high the SC relaying scheme is sufficient to provide satisfactory performance such that the complexity of relays can be effectively reduced
A visual_representation for knowledge structures
knowledge-based_systems often represent their knowledge as a network of interrelated units Such networks are commonly presented to the user as a diagram of nodes connected by lines These diagrams have provided a powerful visual metaphor for knowledge_representation However their complexity can easily become unmanageable as the knowledge_base KB grows This paper describes an alternate visual_representation for navigating knowledge structures based on a virtual museum metaphor This representation uses nested boxes rather than linked nodes to represent relations The intricate structure of the knowledge_base is conveyed by a combination of position size color and font cues MUE Museum Unit Editor was implemented using this representation to provide a graphic front end for the Cyc knowledge_base
Variety Is the Spice of Virtual Life
Before an environment can be populated with characters a set of models must first be acquired and prepared Sometimes it may be possible for artists to create each virtual character individually - for example if only a small number of individuals are needed or there are many artists available to create a larger population of characters However for most applications that need large and heterogeneous groups or crowds more automatic methods of generating large numbers of humans animals or other characters are needed Fortunately depending on the context it is not the case that all types of variety are equally important Sometimes quite simple methods for creating variations which do not over-burden the computing_resources available can be as effective as and perceptually equivalent to far more resource-intensive approaches In this paper we present some recent research and development efforts that aim to create and evaluate variety for characters in their bodies faces movements behaviours and sounds
Finite horizon linear quadratic regulation for linear discrete_time-varying systems with single multiple input delay s
This paper studies the linear quadratic regulation problem for linear discrete_time-varying systems with one or multiple delays in control input This type of input-delay system can be used to model delayed actuation where the system depends on the input after various could be more than one time_delays We provide explicit forms of the finite horizon closed-loop optimal_control laws numerical_examples are also provided to show the performance of our derived control laws
VirusMeter Preventing Your Cellphone from Spies
Due to the rapid advancement of mobile_communication technology mobile_devices nowadays can support a variety of data services that are not traditionally available With the growing popularity of mobile_devices in the last few years attacks targeting them are also surging Existing mobile malware_detection techniques which are often borrowed from solutions to Internet malware_detection do not perform as effectively due to the limited computing_resources on mobile_devices R N R N In this paper we propose VirusMeter a novel and general malware_detection method to detect anomalous_behaviors on mobile_devices The rationale underlying VirusMeter is the fact that mobile_devices are usually battery powered and any malicious activity would inevitably consume some battery power By monitoring power consumption on a mobile_device VirusMeter catches misbehaviors that lead to abnormal power consumption For this purpose VirusMeter relies on a concise user-centric power model that characterizes power consumption of common user behaviors In a real-time mode VirusMeter can perform fast malware_detection with trivial runtime overhead When the battery is charging referred to as a battery-charging mode VirusMeter applies more sophisticated machine_learning_techniques to further improve the detection_accuracy To demonstrate its feasibility and effectiveness we have implemented a VirusMeter prototype on Nokia 5500 Sport and used it to evaluate some real cellphone malware including FlexiSPY and Cabir Our experimental results show that VirusMeter can effectively detect these malware activities with less than 1 5 additional power consumption in real time
Author Profiling for Vietnamese Blogs
This paper presents the first work in the task of author profiling for Vietnamese blogs This task is important in threat identification and marketing intelligence We have developed a Vietnamese Blog Profiling framework to automatically predict age gender geographic origin and occupation of weblogs authors purely based on language use The experiments on the blogs corpus we collected show very promising results with accuracy of around 80 across all traits
Integrating heterogeneous personal devices with public display-based information services
Based on a requirements_analysis for public location_information displays in on-campus settings we describe the implementation of a system_called SynchroBoard Especially we elaborate on mechanisms to integrate different personal devices in this framework
performance_analysis of wireless fair queuing algorithms with compensation mechanism
Scheduling packet transmission over wireless_links requires quantification of the QoS performance such as delay and packet_loss in terms of known system parameters One of the key issues is how to account for effects of the compensation mechanism on the system s QoS performance In this paper we develop a model namely the two-stage tandem queuing TSTQ to characterize the behaviors of packet flows in the system which applies the wireless fair scheduling with the compensation mechanism Using queueing_analysis we derive performance parameters average delay and packet_loss_rate in closed-form_expressions These expressions are functions of the source wireless_channel and compensation mechanism parameters Moreover the trade-off relationship between delay and packet_loss_rate is revealed which is controlled by the parameter of lagging bound Numerical and simulation results are used to verify the validity of the modeling_and_analysis work
channel_assignment for wireless_networks Modelled as d-Dimensional Square Grids
In this paper we study the problem of channel_assignment for wireless_networks modelled as d-dimensional grids In particular for d-dimensional square grids we present optimal assignments that achieve a channel separation of 2 for adjacent stations where the reuse distance is 3 or 4 We also introduce the notion of a colouring schema for d- dimensional square grids and present an algorithm that assigns colours to the vertices of the grid satisfying the schema constraints
Efficient Implementation of the Overlap Operator on Multi-GPUs
Lattice QCD calculations were one of the first applications to show the potential of GPUs in the area of high performance computing Our interest is to find ways to effectively use GPUs for lattice calculations using the overlap operator The large memory footprint of these codes requires the use of multiple GPUs in parallel In this paper we show the methods we used to implement this operator efficiently We run our codes both on a GPU cluster and a CPU cluster with similar interconnects We find that to match performance the CPU cluster requires 20-30 times more CPU cores than GPUs
Flat vs symbiotic evolutionary subspace clusterings
Subspace clustering coevolves the attribute space supporting clusters at the same time as parameterizing the cluster location and combination Typically a flat representation is pursued in which individuals describe both the property of individual clusters as well as the combination of clusters used to define the overall solution hereafter F-ESC Conversely a symbiotic approach was recently proposed in which candidate clusters and the combination of clusters are coevolved from independent populations hereafter S-ESC In this work a common framework is pursued in order for flat and symbiotic evolutionary subspace clustering to be compared directly We show that F-ESC might match S-ESC results for data sets with high proportions of cluster support however the gap between the two algorithm increases as cluster support decreases
Context-Dependent Force-Feedback Steering Wheel to Enhance Drivers On-Road Performances
In this paper the topic of the augmented cognition applied to the driving task and specifically to the steering maneuver is discussed We analyze how the presence of haptic_feedback on the steering wheel could help drivers to perform a visually-guided task by providing relevant information like vehicle speed and trajectory Starting from these considerations a Context-Dependant Steering Wheel force_feedback CDSW had been developed able to provide to the driver the most suitable feeling of the vehicle dynamics according to the driven context With a driving simulator the CSWD software had been tested twice and then compared with a traditional steering wheel
Direct segmentation of smooth multiple point regions
The purpose of reverse_engineering is to convert a large point_cloud into an accurate fair and consistent CAD model For a class of conventional engineering objects we have the a priori assumption that the object is bounded exclusively by simple analytic surfaces In this case it is possible to generate the model with a minimal amount of user interaction The key issue is segmentation i e to separate the point_cloud into smaller regions where each can be approximated by a single surface While this is relatively simple where the regions are bounded by sharp edges problems arise when smoothly connected regions need to be separated The direct segmentation method described in this paper is based on a special sequence of tests by means of which a large point_cloud can be robustly splitted into smaller subregions until no further subdivision is possible Surfaces of linear extrusion and revolution are also detected The structure of the smooth multiple regions is the basis of constrained surface_fitting in the final model building phase
Research on Dynamic Reputation Management Model Based on PageRank
For the purpose of developing a usable trust_relationship between the resource providers hosts and the resource consumers users in an open computing environment and providing a unified management of the reputation degree of the resource provides and users a dynamic reputation management model based on Google PageRank DRMPR is proposed The DRMPR system can achieve self-study from a large amount of data and feedback and with the system obtaining a plenty of resources the judgment is more accurate At the end of the paper an experimental project has been built to demonstrate that the DRMPR can provide a unified management of the reputation degree of the resource provides and users accurately
Parameterization of the MISO IFC rate region the case of partial_channel_state_information
We study the achievable_rate_region of the multiple-input single-output MISO interference_channel IFC under the assumption that all receivers treat the interference as additive_gaussian_noise We assume the case of two users and that the channel_state_information CSI is only partially known at the transmitters Our main result is a characterization of Pareto-optimal transmit strategies for channel_matrices that satisfy a certain technical condition numerical_examples are provided to illustrate the theoretical_results
Introducing a rasch-type anthropomorphism scale
In human-robot_interaction research much attention is given to the extent to which people perceive humanlike attributes in robots Generally the concept anthropomorphism is used to describe this process Anthropomorphism is defined in different ways with much focus on either typical human attributes or uniquely human attributes This difference has caused different measurement tools to be developed We argue that anthropomorphism can best be described as a continuum ranging from low to high human likeness and should be measured accordingly We found that anthropomorphic characteristics can be invariantly ordered according to the ease with which these can be ascribed to robots
Knowledge formation and dialogue using the KRAKEN toolset
The KRAKEN toolset is a comprehensive interface for knowledge_acquisition that operates in conjunction with the Cyc knowledge_base The KRAKEN system is designed to allow subject-matter experts to make meaningful additions to an existing knowledge_base without the benefit of training in the areas of artificial_intelligence ontology_development or logical representation Users interact with KRAKEN via a natural-language interface which translates back and forth between English and the KB s logical representation language A variety of specialized tools are available to guide users through the process of creating new concepts stating facts about those concepts and querying the knowledge_base KRAKEN has undergone two independent performance evaluations In this paper we describe the general structure and several of the features of KRAKEN focussing on key aspects of its functionality in light of the specific knowledge-formation and acquisition challenges they are intended to address
APTEEN A Hybrid Protocol for efficient_routing and Comprehensive information_retrieval in wireless_sensor_networks
wireless_sensor_networks with thousands of tiny sensor_nodes are expected to find wide applicability and increasing deployment in coming years as they enable reliable monitoring and analysis of the environment In this paper we propose a hybrid routing_protocol APTEEN which allows for comprehensive information_retrieval The nodes in such a network not only react to time-critical situations but also give an overall picture of the network at periodic intervals in a very energy efficient manner Such a network enables the user to request past present and future data from the network in the form of historical one-time and persistent queries respectively We evaluated the performance of these protocols and observe that these protocols are observed to outperform existing protocols in terms of energy consumption and longevity of the network
Motion parameter estimation of multiple ground_moving_targets in multi-static passive_radar_systems
Multi-static passive_radar MPR systems typically use narrowband signals and operate under weak signal conditions making them difficult to reliably estimate motion parameters of ground_moving_targets On the other hand the availability of multiple spatially separated illuminators of opportunity provides a means to achieve multi-static diversity and overall signal enhancement In this paper we consider the problem of estimating motion parameters including velocity and acceleration of multiple closely located ground_moving_targets in a typical MPR platform with focus on weak signal conditions where traditional time-frequency_analysis-based methods become unreliable or infeasible The underlying problem is reformulated as a sparse signal_reconstruction problem in a discretized parameter search space While the different bistatic links have distinct Doppler signatures they share the same set of motion parameters of the ground_moving_targets Therefore such motion parameters act as a common sparse support to enable the exploitation of group sparsity-based methods for robust motion parameter estimation This provides a means of combining signal energy from all available illuminators of opportunity and thereby obtaining a reliable estimation even when each individual signal is weak Because the maximum_likelihood ML estimation of motion parameters involves a multi-dimensional search and its performance is sensitive to target_position errors we also propose a technique that decouples the target motion parameters yielding a two-step process that sequentially estimates the acceleration and velocity vectors with a reduced dimensionality of the parameter search space We compare the performance of the sequential method against the ML estimation with the consideration of imperfect knowledge of the initial target_positions The cramer-rao_bound CRB of the underlying parameter estimation problem is derived for a general multiple-target scenario in an MPR system Simulation results are provided to compare the performance of the sparse signal_reconstruction-based methods against the traditional time-frequency-based methods as well as the CRB
Topology Preserving Marching Cubes-like Algorithms on the Face-Centered Cubic Grid
The well-known marching cubes algorithm is modified to apply to the face-centered cubic fee grid Thus the local configurations that are considered when extracting the local surface patches are not cubic anymore This paper presents three different partitionings of the fee grid to be used for the local configurations The three candidates are evaluated theoretically and experimentally and compared with the original marching cubes algorithm It is proved that the reconstructed surface is topologically equivalent to the surface of the original object when the surface of the original object that is digitized is smooth and a sufficiently dense fee grid is used
An on-line signature verification system based on fusion of local and global information
An on-line signature verification system exploiting both local and global information through decision-level fusion is presented Global information is extracted with a feature-based representation and recognized by using Parzen Windows Classifiers Local information is extracted as time functions of various dynamic properties and recognized by using hidden_markov_models Experimental results are given on the large MCYT signature database 330 signers 16500 signatures for random and skilled forgeries feature_selection experiments based on feature_ranking are carried out It is shown experimentally that the machine expert based on local information outperforms the system based on global analysis when enough training data is available Conversely it is found that global analysis is more appropriate in the case of small training_set size The two proposed systems are also shown to give complementary recognition information which is successfully exploited using decision-level score fusion
Tumor-Immune Interaction Surgical Treatment and Cancer Recurrence in a Mathematical Model of Melanoma
Malignant melanoma is a cancer of the skin arising in the melanocytes We present a mathematical model of melanoma invasion into healthy tissue with an immune response We use this model as a framework with which to investigate primary tumor invasion and treatment by surgical excision We observe that the presence of immune cells can destroy tumors hold them to minimal expansion or through the production of angiogenic factors induce tumorigenic expansion We also find that the tumor immune system dynamic is critically important in determining the likelihood and extent of tumor regrowth following resection We find that small metastatic lesions distal to the primary tumor mass can be held to a minimal size via the immune interaction with the larger primary tumor numerical_experiments further suggest that metastatic disease is optimally suppressed by immune activation when the primary tumor is moderately rather than minimally metastatic Furthermore satellite lesions can become aggressively tumorigenic upon removal of the primary tumor and its associated immune tissue This can lead to recurrence where total cancer mass increases more quickly than in primary tumor invasion representing a clinically more dangerous disease state These results are in line with clinical case studies involving resection of a primary melanoma followed by recurrence in local metastases
Metric rectification for perspective images of planes
We describe the geometry constraints and algorithmic implementation for metric rectification of planes The rectification allows metric properties such as angles and length ratios to be measured on the world plane from a perspective image The novel contributions are first that in a stratified context the various forms of providing metric information which include a known angle two equal though unknown angles and a known length ratio can all be represented as circular constraints on the parameters of an affine transformation of the plane-this provides a simple and uniform framework for integrating constraints second direct rectification from right angles in the plane third it is shown that metric rectification enables calibration of the internal camera parameters fourth vanishing points are estimated using a maximum_likelihood_estimator fifth an algorithm for automatic rectification Examples are given for a number of images and applications demonstrated for texture map acquisition and metric measurements
Improved pairwise_key_establishment for wireless_sensor_networks
Due to the resource constraints pre-distributing secret_keys into sensor_nodes before they are deployed is an applicable approach to achieve information_security in wireless_sensor_networks Several key_pre-distribution schemes have been proposed in literature to establish pairwise_keys between sensor_nodes they are either too complicated or insecure for some common attacks To address these weaknesses we propose an improved pairwise_key_establishment mechanism for wireless_sensor_networks in this paper Compared with existing approaches our scheme has better network resilience against node_capture_attack Analysis and simulation results show that our scheme performs better than earlier proposed schemes in terms of network connectivity key storage_overhead maximum supported network size computational and communication_overheads
Applications of Plotkin-terms partitions and morphisms for closed terms
This theoretical pearl is about the closed term model of pure untyped lambda-terms modulo β-convertibility A consequence of one of the results is that for arbitrary distinct combinators closed lambda terms M M N N there is a combinator H such thatdisplay formula hereThe general result which comes from Statman 1998 is that uniformly r e partitions of the combinators such that each block is closed under β-conversion are of the form H 1 M M ΛΦ This is proved by making use of the idea behind the so-called Plotkin-terms originally devised to exhibit some global but non-uniform applicative behaviour For expository reasons we present the proof below The following consequences are derived a characterization of morphisms and a counter-example to the perpendicular lines lemma for β-conversion
Cost Revenue Optimisation of Multi-Service Cellular Planning for City Centre E-UMTS
An overview of all-IP enhanced Universal Mobile Telecommunication System E-UMTS service needs in the business city centre BCC scenario is first presented Then E-UMTS traffic generation and activity_models are described and characterised system_level_simulations are carried out and the enhanced performance is demonstrated based in a single quality parameter which simultaneously accounts for call blocking and handover failure probabilities end-to-end_delays do not present a limitation By considering a grade of service of 1 for the quality parameter and different hypothesis for costs and prices an optimum coverage distance is obtained around 200-425 m which maximises the supported throughput per km 2 However results for the profit in percentage indicates that coverage distances in the range 395-425 m should be used in BCC
Implementing fault-tolerance in real-time_systems by automatic program transformations
We present a formal_approach to implement and certify fault-tolerance in real-time_embedded_systems The fault-intolerant initial system consists of a set of independent periodic_tasks scheduled onto a set of fail-silent processors We transform the tasks such that assuming the availability of an additional spare processor the system tolerates one failure at a time transient or permanent Failure detection is implemented using heartbeating and failure masking using checkpointing and roll-back These techniques are described and implemented by automatic program transformations on the tasks programs The proposed formal_approach to fault-tolerance by program transformation highlights the benefits of separation_of_concerns and allows us to establish correctness properties
Using literature-based discovery to identify disease candidate genes
Summary We present BITOLA an interactive literature-based biomedical discovery support system The goal of this system is to discover new potentially meaningful relations between a given starting concept of interest and other concepts by mining the bibliographic_database MEDLINE To make the system more suitable for disease candidate gene discovery and to decrease the number of candidate relations we integrate background_knowledge about the chromosomal location of the starting disease as well as the chromosomal location of the candidate genes from resources such as LocusLink and human_genome Organization HUGO BITOLA can also be used as an alternative way of searching the MEDLINE database The system is available at http www mf uni-lj si bitola
Modeling nondisclosure in terms of the subject-instruction stream
A formal definition is given of nondisclosure for a computing_system and the author describes a functional decomposition of the system into two kinds of activities namely the selection and execution of subject instructions security_requirements for each of the two resulting subsystems are given and it is proved that if each subsystem satisfies its security_requirements then the entire system satisfies the given nondisclosure_property Finally in order to show how security can be enforced by the system an access-control model is given for subject-instruction processing that guarantees satisfaction of the given security_requirements for subject-instruction processing
Galois theory and a new homotopy double groupoid of a map of spaces
The authors have used generalised Galois Theory to construct a homotopy double groupoid of a surjective Þbration of Kan simplicial sets Here we apply this to construct a new homotopy double groupoid of a map of spaces which includes constructions by others of a 2-groupoid cat 1 -group or crossed module An advantage of our construction is that the double groupoid can give an algebraic model of a foliated bundle 1
Lane-Change Decision Aid System Based on Motion-Driven vehicle_tracking
Overtaking and lane changing are very dangerous driving maneuvers due to possible driver distraction and blind spots We propose an aid system based on image_processing to help the driver in these situations The main purpose of an overtaking monitoring system is to segment the rear view and track the overtaking vehicle We address this task with an optic-flow-driven scheme focusing on the visual field in the side mirror by placing a camera on top of it When driving a car the ego-motion optic-flow pattern is very regular i e all the static_objects such as trees buildings on the roadside or landmarks move backwards An overtaking vehicle on the other hand generates an optic-flow pattern in the opposite direction i e moving forward toward the vehicle This well-structured motion scenario facilitates the segmentation of regular motion patterns that correspond to the overtaking vehicle Our approach is based on two main processing stages First the computation of optical_flow in real time uses a customized digital_signal_processor DSP particularly designed for this task and second the tracking stage itself based on motion pattern analysis which we address using a standard processor We present a validation benchmark scheme to evaluate the viability and robustness of the system using a set of overtaking vehicle sequences to determine a reliable vehicle-detection distance
Inquire predicate-based use and reuse
There are four fundamental aspects of use and reuse in building systems from components conceptualization retrieval selection and correct use The most important barrier to use and reuse is that of conceptualization The Inscape environment is a specification-based software_development environment integrated by the constructive use of formal interface specifications The purpose of the formal interface specifications and the semantic interconnections is to make explicit the invisible semantic dependencies that result in conventionally-built systems The important ingredient provided by Inquire in conceptualization retrieval selection and use is the set of predicates that describe the semantics of the elements in the interface These predicates define the abstractions that are germane to the module interface and describe the properties of data objects and the assumptions and results of operations in a module Use and reuse of components is based on a component s ability to provide needed semantics at a particular point in a system It is the purpose of Inquire the browser and predicate-based search mechanism to aid both the environment and the user in the search for the components that will provide the desired predicates that are required to build and evolve an implementation correctly
Least squares detection of multiple changes in fractional ARIMA processes
We address the problem of estimating changes in fractional integrated ARMA FARIMA processes These changes may be in the long range dependence LRD parameter or the ARMA parameters The signal is divided into elementary segments the objective is then to estimate the segments in which the changes occur This estimation is achieved by minimizing a penalized least-squares criterion based on the parameter estimates computed in each segment The optimization problem is then solved using a dynamic programming algorithm Simulation results on synthetic_data computer_network_traffic are reported
Shape from point features
We present a nonparametric and efficient method for shape localization that improves on the traditional sub-window search in capturing the fine geometry of an object from a small number of feature points Our method implies that the discrete set of features capture more appearance and shape_information than is commonly exploited We use the a-complex by Edelsbrunner et al to build a filtration of simplicial complexes from a user-provided set of features The optimal value of a is determined automatically by a search for the densest complex connected component resulting in a parameter-free algorithm Given K features localization occurs in O K logK time For VGA-resolution images computation takes typically less than 10 milliseconds We use our method for interactive object cut with promising results
formation_control for cooperative containment of a diffusing substance
We present a decentralized controller to keep a group of agents at equal spacing while moving around the perimeter of a loop defined by a constant distance from a convex polygon motivated by a cooperative containment problem Traveling at constant speed the agents achieve and maintain their formation by using small steering adjustments to equalize the distance between themselves and their respective leading and following neighbors Since the formation moves around a common loop an agent can move forward or back in formation by respectively steering slighting inside or outside the reference loop These adjustments are controlled with the use of variable radius parameters for each agent that are shown to converge to the desired reference loop as equal spacing is achieved We show that the proposed controller renders the desired formation locally asymptotically_stable and provide simulations to demonstrate the performance of the controller for an example scenario in which the formation must recover from the loss of an agent
A Consensus Support System Model for group_decision-making Problems With Multigranular Linguistic Preference Relations
The group_decision-making framework with linguistic preference relations is studied In this context we assume that there exist several experts who may have different background and knowledge to solve a particular problem and therefore different linguistic term sets multigranular linguistic information could be used to express their opinions The aim of this paper is to present a model of consensus support system to assist the experts in all phases of the consensus reaching process of group_decision-making problems with multigranular linguistic preference relations This consensus support system model is based on i a multigranular linguistic methodology ii two consensus criteria consensus degrees and proximity measures and iii a guidance advice system The multigranular linguistic methodology permits the unification of the different linguistic domains to facilitate the calculus of consensus degrees and proximity measures on the basis of experts opinions The consensus degrees assess the agreement amongst all the experts opinions while the proximity measures are used to find out how far the individual opinions are from the group opinion The guidance advice system integrated in the consensus support system model acts as a feedback mechanism and it is based on a set of advice rules to help the experts change their opinions and to find out which direction that change should follow in order to obtain the highest degree of consensus possible There are two main advantages provided by this model of consensus support system_firstly its ability to cope with group_decision-making problems with multigranular linguistic preference relations and secondly the figure of the moderator traditionally presents in the consensus reaching process is replaced by the guidance advice system and in such a way the whole group_decision-making process is automated
An Aspect-Oriented Approach to Resource Composition in petri_net-based Software architectural_models
petri_net has been widely used for modeling software_systems due to its mathematical soundness and support of various tools In many cases performance-related analyses of petri_net for a software system need to consider the resource limitations caused by a specific platform In terms of aspect-oriented approach the interference of various resources scattered across a software system can be regarded as a specific concern that is only necessary during its performance-related analysis process To capture the interactions of resources within the petri_net-based software architectural_model we propose an aspect-oriented resource composition model and the XML-based representation language called the resource extension markup language ReML for its description In our approach one or more resource composition models can be developed and described in ReML separately from the development of base software architectural_models Through the weaving process a resource composition model can be applied to extend several petri_net-based software architectural_models The resource weaver generates an augmented petri_net used for analyzing performance characteristics of the extended software architectural_model with resource interactions Our aspect-oriented approach facilitates selecting an optimal or superior resource composition model for a software architectural_model and vice versa which is illustrated using two exemplary server models
Building sub-knowledge_bases using concept_lattices
A theory of concept Galois lattices was first introduced by Wille An extension of his work to simple structures called concept sublattices has also been published This paper shows that concept sublattices can be applied to i determining subsumption of specifications and ii decomposing specifications in terms of others I show that the latter application of the theory may provide us with new conceptualizations of a specification
Coordination strategies for networked_control_systems A power system application
In this paper we present a distributed supervisory strategy for load_frequency_control_problems in networked multi-area power systems Coordination between the control center and the areas is accomplished via data networks subject to communication latency which is modelled by time-varying time-delay The aim here is at finding strategies able of reconfiguring whenever necessary in response to unexpected load changes and or faults the nominal set-points on frequency and generated power of each area so that viable evolutions arise for the overall networked system and a new suitable equilibrium is reached
Cross-talk attack monitoring and localization in all-optical_networks
The effects of an attack connection can propagate quickly to different parts of an all-optical transparent network Such attacks affect the normal traffic and can either cause service degradation or outright service denial Quick detection and localization of an attack source can avoid losing large amounts of data in an all-optical_network_attack monitors can collect the information from connections and nodes for diagnostic purpose However to detect attack sources it is not necessary to put monitors at all nodes Since those connections affected by the attack connection would provide valuable information for diagnosis we show that by placing a relatively small number of monitors on a selected set of nodes in a network is sufficient to achieve the required level of performance However the actual monitor placement routing and attack diagnosis are challenging problems that need research attention In this paper we first develop our models of crosstalk attack and monitor node With these models we prove the necessary and sufficient condition for one-crosstalk-attack diagnosable networks Next we develop a scalable diagnosis method which can localize the attack connection efficiently with sparse monitor nodes in the network
adaptive_algorithms for balanced multidimensional clustering
The G-K-D tree generalized K-D tree method aims at reducing the average number of data page accesses per query but it ignores the cost of index search The authors propose two adaptive_algorithms that take into consideration both data page access cost and index page access cost It attempts to find a minimum total cost Experimental results indicate that the proposed algorithms are superior to the G-K-D tree method
An optimized stereo_vision implementation for embedded_systems application to RGB and Infra-Red images
The aim of this paper is to demonstrate the applicability and the effectiveness of a computationally demanding stereo-matching_algorithm in different low-cost and low-complexity embedded_devices by focusing on the analysis of timing and image_quality performances Various optimizations have been implemented to allow its deployment on specific hardware_architectures while decreasing memory and processing time requirements 1 reduction of color channel information and resolution for input images 2 low-level software optimizations such as parallel_computation replacement of function calls or loop unrolling 3 reduction of redundant data structures and internal data representation The feasibility of a stereo_vision_system on a low-cost platform is evaluated by using standard datasets and images taken from infra-red_cameras Analysis of the resulting disparity_map accuracy with respect to a full-size dataset is performed as well as the testing of suboptimal_solutions
Parametric Mixing for Centralized VOIP Conferencing using ITU-T Recommendation G 722 2
VoIP conferencing with a centralized speech mixing bridge introduces additional end-to-end latency into packetized voice communication This paper investigates how full tandem speech decoding time-domain mixing speech encoding cycle can be circumvented by instead extracting the coded speech parameters and performing the speech packet mixing without time-domain reconstruction By mixing through coded speech parameters we show that nearly an 85 decrease in computational complexity can be achieved over full tandem mixing of two speakers for G 722 2 thus significantly reducing the packet latency at the centralized speech mixing bridge For the G 722 2 parametric mixer presented linear prediction coefficients LPCs pitch lags fixed codebooks and gains are extracted without full speech reconstruction from the encoded bit_stream mixed and then re-encoded instead of the full tandem approach where each speech frame must be fully reconstructed We investigate the mixing in two scenarios i mix two 12 65 kbps G 722 2 speech streams at a mixed rate of 12 65 kbps and ii mix two 12 65 kbps G 722 2 speech streams at a mixed rate of 18 25 kbps PAMS is used to evaluate the speech_quality of the parametric mixer resulting in an average distortion of 0 37 MOS compared to tandem mixing as shown by simulations using typical conversation models
Self-adaptive on-line reclustering of complex object_data
A likely trend in the development of future CAD CASE and office information_systems will be the use of object-oriented_database_systems to manage their internal data stores The entities that these applications will retrieve such as electronic parts and their connections or customer_service records are typically large complex objects composed of many interconnected heterogeneous objects not thousands of tuples These applications may exhibit widely shifting usage patterns due to their interactive_mode of operation Such a class of applications would demand clustering_methods that are appropriate for clustering large complex objects and that can adapt on-line to the shifting usage patterns While most object-oriented clustering_methods allow grouping of heterogeneous objects they are usually static and can only be changed off-line We present one possible architecture for performing complex object reclustering in an on-line manner that is adaptive to changing usage patterns Our architecture involves the decomposition of a clustering_method into concurrently operating components that each handle one of the fundamental_tasks involved in reclustering namely statistics collection cluster_analysis and reorganization We present the results of an experiment performed to evaluate its behavior These results show that the average miss rate for object accesses can be effectively reduced using a combination of rules that we have developed for deciding when cluster analyses and reorganizations should be performed
Reim ReImInfer checking and inference of reference immutability and method purity
Reference immutability ensures that a reference is not used to modify the referenced object and enables the safe sharing of object structures A pure method does not cause side-effects on the objects that existed in the pre-state of the method execution Checking and inference of reference immutability and method purity enables a variety of program analyses and optimizations We present ReIm a type_system_for reference immutability and ReImInfer a corresponding type_inference analysis The type_system is concise and context-sensitive The type_inference analysis is precise and scalable and requires no manual annotations In addition we present a novel application of the reference immutability type_system method purity inference To support our theoretical_results we implemented the type_system and the type_inference analysis for Java We include a type checker to verify the correctness of the inference result Empirical results on java_applications and libraries of up to 348kLOC show that our approach achieves both scalability and precision
MODEL-FREE CONTROL AND INTELLIGENT pid_controllers TOWARDS A POSSIBLE TRIVIALIZATION OF nonlinear_control
We are introducing a model-free control and a control with a restricted model for finite-dimensional complex systems This control_design may be viewed as a contribution to intelligent pid_controllers the tuning of which becomes quite straightforward even with highly nonlinear and or time-varying systems Our main tool is a newly developed numerical differentiation Differential algebra provides the theoretical framework Our approach is validated by several numerical_experiments
modified_differential_evolution for constrained_optimization
In this paper we present a Differential-Evolution based approach to solve constrained_optimization_problems The aim of the approach is to increase the probability of each parent to generate a better offspring This is done by allowing each solution to generate more than one offspring but using a different mutation_operator which combines information of the best solution in the population and also information of the current parent to find new search directions Three selection criteria based on feasibility are used to deal with the constraints of the problem and also a diversity mechanism is added to maintain infeasible solutions located in promising areas of the search space The approach is tested in a set of test problems proposed for the special session on Constrained Real Parameter Optimization The results obtained are discussed and some conclusions are established
Performance Evaluation of Piggyback Requests in IEEE 802 16
WiMAX worldwide_interoperability_for_microwave_access is a wireless access_technology that aims to provide last mile wireless broadband_access for fixed and mobile_users as an alternative to the wired DSL and cable access It is specified in the IEEE 802 16 standard The standard defines several possible bandwidth_request methods that can be implemented in an actual deployment of a WiMAX network In this paper we will study the performance of two different bandwidth_request mechanisms namely piggyback and broadcast requests and will show in which situations piggybacking performs better than the contention based broadcast bandwidth_requests
Use of coded infrared light as artificial landmarks for mobile_robot_localization
This paper presents mobile_robot_localization using coded infrared light as artificial landmarks Different from RFID identification using infrared light has highly deterministic characteristics IRID infrared identification is implemented with IR LEDs and photo transistors By putting several infrared LEDs on the ceiling the floor is divided into several sectors and each sector is set to have a unique identification The coded infrared light tells which sector the robot is in but the size of the uncertainty is still too large if the sector size is large which usually occur Dead-reckoning provides the estimated robot configuration but the error is getting accumulated as the robot travels This paper presents an algorithm which fuses both the encoder and the IRID information so that the size of the uncertainty becomes smaller It also introduces a framework which can be used with other types of the artificial landmarks The characteristics of the developed IRID and the proposed algorithm are verified from the experiments
The growth of international collaboration in East European scholarly communities a bibliometric analysis of journal articles published between 1989 and 2009
In the last two decades international collaboration in the Eastern European academic communities has strongly intensified Scientists from developed countries within the European Union play a key role in stimulating the international collaboration of academics in this region In addition many of the research projects that engage East-European scholars are only possible in the framework of the large European programmes The present study focuses on the role of EU and other developed nations as a partner of these countries and the analysis of the performance of collaborative research as reflected by the citation impact of internationally co-authored publications
INEXACT KLEINMAN-NEWTON METHOD FOR riccati_equations
In this paper we consider the numerical_solution of the algebraic riccati_equation using Newton s method We propose an inexact variant which allows one control the number of the inner iterates used in an iterative solver for each Newton step Conditions are given under which the monotonicity and global convergence result of Kleinman also hold for the inexact Newton iterates numerical_results illustrate the efficiency of this method
dimensional_synthesis of a 3-DOF parallel_manipulator
kinematics_analysis and dimensional_synthesis are two important problems of a parallel_manipulator dimensional_synthesis is optimization of the kinematic parameters according to desired workspace or other design requirements In this paper the dimensional_synthesis of a 3-DOF parallel_manipulator which mimics DELTA robots is studied considering maximum inscribed workspace and reciprocal of the condition_number on the workspace section based on the concept The kinematic model of the 3-DOF parallel_manipulator is given at first The golden section search is used to search the workspace of the manipulator and mesh the boundary Then the algorithm for calculating the inscribed workspace and dimensional_synthesis considering the inscribed workspace are presented Thirdly the distribution of dexterity index on the workspace section and dimensional_synthesis considering the reciprocal of condition_number is studied The two_dimensional_synthesis results are compared at the end of the paper While the synthesis methodology of the manipulator is studied It is helpful to improve design efficiency of the 3-DOF parallel_manipulator The quickly design for the manipulator can be performed through the proposed methods of dimensional_synthesis
kinematics_analysis for obstacle-climbing performance of a rescue robot
A tracked robot is designed for destroyed mine search and rescue The mechanical_system is introduced from reconfigurable structure suspension_system and anti- explosive and waterproof The sensors include CCD camera CO CH4 temperature and air speed are equipped on the robot Two pairs of swing arms are equipped on the robot Their motions help robot climb up obstacle Because the center of gravity CG plays an important role in the process of climbing up an obstacle the CG kinematics model is built Using this model the CG change situation is obtained and the maximum height of the obstacle which can be climbed up is obtained and the stability angle margin is obtained too The relationship between the robot pitch angle and the height of the obstacle is obtained Using this relationship the geometry parameter of the uncertain environment can be known These analysis help to design_and_control the robot
Dynamic software updates a VM-centric approach
Software evolves to fix bugs and add features Stopping and restarting programs to apply changes is inconvenient and often costly Dynamic software updating DSU addresses this problem by updating programs while they execute but existing DSU systems for managed languages do not support many updates that occur in practice and are inefficient This paper presents the design and implementation of J volve a DSU-enhanced Java VM Updated programs may add delete and replace fields and methods anywhere within the class hierarchy Jvolve implements these updates by adding to and coordinating VM classloading just-in-time compilation scheduling return barriers on-stack replacement and garbage collection J volve is safe its use of bytecode verification and VM thread synchronization ensures that an update will always produce type-correct executions Jvolve is flexible it can support 20 of 22 updates to three open-source programs--Jetty web_server JavaEmailServer and CrossFTP server--based on actual releases occurring over 1 to 2 years Jvolve is efficient performance experiments show that incurs no overhead during steady-state execution These results demonstrate that this work is a significant step towards practical support for dynamic updates in virtual_machines for managed languages
Creating Rule Ensembles from Automatically-Evolved rule_induction Algorithms
Ensembles are a set of classification_models that when combined produce better predictions than when used by themselves This chapter proposes a new evolutionary_algorithm-based method for creating an ensemble of rule sets consisting of two stages First an evolutionary_algorithm more precisely a genetic_programming algorithm is used to automatically create complete rule_induction algorithms Secondly the automatically-evolved rule_induction algo- rithms are used to produce rule sets that are then combined into an ensemble Concerning this second stage we investigate the effectiveness of two different approaches for combining the votes of all rule sets in the ensemble and two dif- ferent approaches for selecting which subset of evolved rule_induction algorithms out of all evolved algorithms should be used to produce the rule sets that will be combined into an ensemble
XML and Meta Data Based EDI for Small Enterprises
Today in many cases electronic_data_interchange EDI is limited to large scale industry connected to their own value added networks Small-scale enterprises are not yet integrated in the communication flow because actual EDI solutions are to complex to inflexible or to expensive R N R N The approach presented in this paper separates knowledge about data structures and data formats from the process of generation of destination files This knowledge is transformed into a meta data structure represented by XML document type definitions DTD which itself are stored within a database system If any changes of the data interchange specification are necessary it is sufficient to update the corresponding meta data information within the XML DTDs The implementation of the data interchange processor remains unchanged This type of adaptation does not require a software specialist and therefore it meets an important requirement of small-scale enterprises Data transmission is done using the advantages of XML and Internet technology
An FPGA-Based embedded_system_for fingerprint_matching Using Phase-Only correlation_algorithm
biometric_identification systems are defined as systems exploiting automated methods of personal recognition based on physiological or behavioural characteristics Among these fingerprints are very reliable biometric identifiers Trying to fasten the image_processing step makes the recognition process more efficient especially concerning embedded_systems for real-time authentication In this paper we propose an FPGA-based architecture that efficiently implements the high computationally demanding core of a matching_algorithm based on phase-only spatial_correlation Moreover we show how it is possible to use COTS components to embed an entire AFIS on chip and so reducing cost space and energy_used
Classification of breast masses in mammograms using neural_networks with shape edge sharpness and texture features
We propose an approach using artificial_neural_networks to classify masses in mammograms as malignant or benign Single- layer and multilayer perceptron networks are used in a study on perceptron topologies and training procedures for pattern classifica- tion of breast masses The contours of a set of 111 regions on mam- mograms related to breast masses and tumors are manually delin- eated and represented by polygonal models for shape analysis Ribbons of pixels are extracted around the boundaries of a subset of 57 masses by dilating and eroding the contours Three shape fac- tors three measures of edge sharpness and 14 texture features based on gray-level co-occurrence matrices of the pixels in the rib- bons are computed Several combinations of the features are used with perceptrons of varying topology and training procedures for the classification of benign masses and malignant tumors The results are compared in terms of the area Az under the receiver operating characteristics curve Values of Az up to 0 99 are obtained with the shape factors and texture features However only feature_sets that included at least one shape factor provide consistently high perfor- mance with respect to variations in network_topology and training
The analysis of the performance of multi-beamforming in memory nonlinear power amplifier
With the increasingly diverse and complex requirements of radar_systems and communication_systems the application of multifunction-phased_array_radar has become a trend and the digital multi-beamforming technology plays a crucial role in it In practice power amplifier PA is an essential component in radar_systems and communication_systems Unfortunately it is always nonlinear to provide a high output power With the purpose of a high output power and efficiency it is necessary to study the influence of PA nonlinear characteristics on the digital multi-beamforming In this paper a form of the multi-beamforming signal and a nonlinear_model with memory for PA are given The output signal via the PA model has been analyzed subsequently As the result of analysis it can be found that the output signal is divided into the original signal and the interferential signal The power ratio of original signal to interference signal can reflect the influence of PA nonlinear characteristics on the digital multi-beamforming Finally according to the ratio the results of computer simulation show that the memory effect plays a key role for the small power signal while the nonlinearity plays an important role for the large power signal
Relaxed multiple routing configurations for IP fast reroute
Multi-topology routing is an increasingly popular ip_network_management concept that allows transport of different traffic types over disjoint network_paths The concept is of particular interest for implementation of IP fast reroute IP FRR First it can support guaranteed instantaneous recovery from any link or node_failure Second different failures result in routing over different network topologies which augments the parameter space for load distribution optimizations Multiple routing configurations MRC is the state-of-the-art IP FRR scheme based on multi-topology routing today In this paper we present a new enhanced IP FRR scheme which we call ldquorelaxed MRCrdquo rMRC rMRC simplifies the topology construction and increases the routing flexibility in each topology According to our experimental evaluation rMRC has several benefits compared to MRC The number of backup topologies required to provide protection against the same set of failures is reduced hence reducing state in routers In addition the backup_paths are shorter and the link_utilization is significantly better
Similarity measures between intuitionistic fuzzy vague sets A comparative analysis
Existing similarity measures between intuitionistic fuzzy sets vague sets are analyzed compared and summarized by their counter-intuitive examples in pattern_recognition The positive aspects of each similarity measure are demonstrated along with counter cases and discussion of the conditions under which each may not work as desired The research presented here could benefit selection and applications of similarity measures for intuitionistic fuzzy sets and vague sets in practice
Distributed approximation of capacitated dominating sets
We study local distributed_algorithms for the capacitated minimum dominating set CapMDS problem which arises in various distributed network applications Given a network graph_g V E and a capacity cap v N for each node v V the CapMDS problem asks for a subset S V of minimal cardinality such that every network node not in S is covered by at least one neighbor in S and every node v S covers at most cap v of its neighbors We prove that in general_graphs and even with uniform capacities the problem is inherently non-local i e every distributed_algorithm achieving a non-trivial approximation_ratio must have a time complexity that essentially grows linearly with the network diameter On the other hand if for some parameter e 0 capacities can be violated by a factor of 1 e CapMDS becomes much more local Particularly based on a novel distributed randomized rounding technique we present a distributed bi-criteria algorithm that achieves an O log Δ -approximation in time O log 3 n log n e where n and Δ denote the number of nodes and the maximal degree in G respectively Finally we prove that in geometric network graphs typically arising in wireless settings the uniform problem can be approximated within a constant factor in logarithmic time whereas the non-uniform problem remains entirely non-local
Using wordnet hypernyms and dependency features for phrasal-level event recognition and type_classification
The goal of this research is to devise a method for recognizing and classifying TimeML events in a more effective way TimeML is the most recent annotation scheme for processing the event and temporal expressions in natural_language_processing fields In this paper we argue and demonstrate that unit feature dependency information and deep-level WordNet hypernyms are useful for event recognition and type_classification The proposed method utilizes various features including lexical semantic and dependency-based combined features The experimental results show that our proposed method outperforms a state-of-the-art approach mainly due to the new strategies Especially the performance of noun and adjective events which have been largely ignored and yet significant is significantly improved
Three-dimensional focusing with multipass sar_data
Deals with the use of multipass synthetic_aperture_radar sar_data in order to achieve three-dimensional tomography reconstruction in presence of volumetric scattering Starting from azimuth- and range-focused sar_data relative to the same area neglecting any mutual interaction between the targets and assuming the propagation in homogeneous media we investigate the possibility to focus the data also in the elevation direction The problem is formulated in the framework of linear inverse_problem and the solution makes use of the singular value decomposition of the relevant operator This allows us to properly take into account nonuniform orbit separation and to exploit a priori knowledge regarding the size of the volume interested by the scattering mechanism thus leading to superresolution in the elevation direction Results obtained on simulated data demonstrate the feasibility of the proposed processing technique
software_component independence
Independence is a fundamental requirement for calculating system reliability from component reliabilities whether in hardware or software_systems Markov analysis is often used in such calculation however procedures as conventionally used do not qualify as nodes in a Markov system We outline the requirements for several classes of component independence and use the CPS continuation passing style transformation to convert conventional procedures into fragments that are appropriate to Markov analysis
Interpolated Allpass Fractional-Delay Filters Using Root Displacement
Fractional-delay filter is the general name given to filters modelling non-integer delays Such filters have a flat phase delay for a wide frequency band with the value of the phase delay approximating the fractional delay A maximally-flat delay IIR fractional-delay filter can be obtained by the Thiran approximation A simple and efficient method for obtaining filters modelling intermediate fractional delays from two Thiran fractional-delay filters is proposed The proposed method allows continuously modifying the fractional delay Computational complexity of the proposed method is discussed A practical application of the method in model-based sound_synthesis is given as an example
MMsINC a large-scale chemoinformatics database
MMsINC http mms dsfarm unipd it MMsINC search is a database of non-redundant richly annotated and biomedically relevant chemical structures A primary goal of MMsINC is to guarantee the highest quality and the uniqueness of each entry MMsINC then adds value to these entries by including the analysis of crucial chemical properties such as ionization and tautomerization processes and the in silico prediction of 24 important molecular properties in the biochemical profile of each structure MMsINC is consequently a natural input for different chemoinformatics and virtual screening applications In addition MMsINC supports various types of queries including substructure queries and the novel molecular scissoring query MMsINC is interfaced with other primary data collectors such as PubChem protein_data_bank PDB the Food and Drug Administration database of approved drugs and ZINC
IBM Solves a Mixed-Integer Program to Optimize Its Semiconductor Supply Chain
IBM Systems and Technology Group uses operations research models and methods extensively for solving large-scale supply chain optimization SCO problems for planning its extended enterprise semiconductor supply chain The large-scale nature of these problems necessitates the use of computationally efficient solution_methods However the complexity of the models makes developing robust solution_methods a challenge We developed a mixed-integer programming MIP model and supporting heuristics for optimizing IBM s semiconductor supply chain We designed three heuristics driven by practical applications for capturing the discrete aspects of the MIP We leverage the model structure to overcome computational hurdles resulting from the large-scale problem IBM uses the model and method daily for operational and strategic_planning decisions and has saved substantial costs
On passivity based control of stochastic port-Hamiltonian systems
This paper introduces Stochastic Port-Hamiltonian Systems SPHS s whose dynamics are described by Ito stochastic_differential_equations SPHS s are extension of the deterministic port-Hamiltonian systems which are used to express various passive systems First we show a necessary and sufficient condition to preserve the stochastic port-Hamiltonian structure of the system under a class of coordinate transformations Second we derive a condition for the system to be stochastic passive Third we equip Stochastic Generalized Canonical Transformations SGCT s which are pairs of coordinate and feedback transformations preserving the stochastic port-Hamiltonian structure Finally we propose a stochastic stabilization framework based on stochastic passivity and SGCT s
A survey of single and multi-hop link schedulers for mmWave wireless systems
wireless_communication at 60GHz aka mmWave provides extremely high data rates i e several Gb s Moreover devices have a much shorter transmission_range as compared to those operating in the 2 4 and 5GHz bands Indeed links can be treated as pseudo-wires with minimal interference leakage As a result future 60GHz systems will have very high spatial reuse This however is at the expense of high propagation loss which can be overcome using directional or smart_antennas Another promising solution is to employ relays to boost the signal of weak links In particular if relays are properly selected they are able to offer higher data rates than direct_links and also help circumvent obstacles To this end we review state-of-the-art schedulers that take advantage of the high spatial re-use afforded by 60GHz wireless systems to activate multiple links within a channel time allocation Moreover we survey works that use passive and active relays to overcome obstacles and to facilitate novel applications We also survey those that maximize both spatial reuse and throughput of both direct and indirect relay_links simultaneously
A data-driven approach for building macroeconomic decision_support_system
More and more economic and financial data have been collected by the governmental departments in China since China started its socialist market economy in late 1980s These government departments in particular the departments in charge of economic_development pay a great attention to the economic information in their decision-making There is an urgent demand for efficient decision_support_systems in macroeconomic decision-making In this paper we present a data-driven approach for building macroeconomic decision_support_system We first give a comprehensive discussion about the basic elements and their data-processing methods for Macroeconomic decision_support_systems according to China s situation These elements include leading indicator system about business cycle state identification of economic movement forecasting of economic trend promotion of successful cases choice of regulation instruments evaluation method of macroeconomic policies Based on the discussion we put forward to a general structure of macroeconomic decision_support_system Premier implementation shows that the structure can not only satisfy the governmental departments demand fairly but also reflect the future trend
tcp_performance in IEEE 802 11-Based ad_hoc_networks with Multiple Wireless Lossy Links
We propose a packet-level model to investigate the impact of channel error on the transmission_control_protocol tcp_performance over IEEE-802 11-based multihop_wireless_networks A Markov renewal approach is used to analyze the behavior of tcp_reno and TCP Impatient NewReno Compared to previous work our main contributions are listed as follows 1 modeling multiple lossy links 2 investigating the interactions among TCP internet_protocol IP and media_access_control mac_protocol layers specifically the impact of 802 11 mac_protocol and dynamic_source_routing dsr_protocol on tcp_throughput performance 3 considering the spatial reuse property of the wireless_channel the model takes into account the different proportions between the interference_range and transmission_range and 4 adopting more accurate and realistic analysis to the fast recovery process and showing the dependency of throughput and the risk of experiencing successive fast retransmits and timeouts on the packet error probability The analytical_results are validated against simulation results by using GloMoSim The results show that the impact of the channel error is reduced significantly due to the packet retransmissions on a per-hop basis and a small bandwidth delay product of ad_hoc_networks The tcp_throughput always deteriorates less than 10 percent with a packet error rate ranging from 0 to 0 1 Our model also provides a theoretical basis for designing an optimum long retry limit for IEEE 802 11 in ad_hoc_networks
Toward Secure Multikeyword Top-k Retrieval over Encrypted cloud_data
cloud_computing has emerging as a promising pattern for data outsourcing and high-quality data services However concerns of sensitive information on cloud potentially causes privacy_problems data_encryption protects data_security to some extent but at the cost of compromised efficiency Searchable symmetric_encryption SSE allows retrieval of encrypted_data over cloud In this paper we focus on addressing data_privacy_issues using SSE For the first time we formulate the privacy_issue from the aspect of similarity relevance and scheme robustness We observe that server-side ranking based on order-preserving encryption OPE inevitably leaks data_privacy To eliminate the leakage we propose a two-round searchable_encryption TRSE scheme that supports top-k multikeyword retrieval In TRSE we employ a vector_space_model and homomorphic_encryption The vector_space_model helps to provide sufficient search accuracy and the homomorphic_encryption enables users to involve in the ranking while the majority of computing work is done on the server side by operations only on ciphertext As a result information leakage can be eliminated and data_security is ensured Thorough security and performance_analysis show that the proposed scheme guarantees high security and practical efficiency
Improved 16-QAM constellation labeling for BI-STCM-ID with the Alamouti scheme
We design constellation labeling maps for bit-interleaved space-time coded_modulation with iterative_decoding BI-STCM-ID over Rayleigh block-fading_channels using the Alamouti scheme and N sub r receive_antennas To achieve the largest asymptotic coding_gain from the constellation labeling we propose a new design criterion that maximizes the -2N sub r -th power mean of the squared Euclidean distances associated with all error-free feedback events in the constellation Based on this power mean criterion we show that the labeling optimization problem falls into the category of quadratic_assignment_problems We propose two novel 16-QAM labeling maps that are particularly designed for N sub r 1 and N sub r 2 respectively numerical_results show that both labeling maps achieve about 1 dB coding_gain over the conventional 16-QAM modified set partitioning labeling
Perfect output_feedback in the Two-User Decentralized interference_channel
In this paper the eta -nash_equilibrium eta -NE region of the two-user Gaussian interference_channel IC with perfect output_feedback is approximated to within 1 bit s Hz and eta arbitrarily close to 1 bit s Hz The relevance of the eta -NE region is that it provides the set of rate pairs that are achievable and stable in the IC when both transmitter receiver pairs autonomously tune their own transmit receive configurations seeking an eta -optimal individual transmission rate Therefore any rate tuple outside the eta -NE region is not stable as there always exists one link able to increase by at least eta bits s Hz its own transmission rate by updating its own transmit receive configuration The main insights that arise from this paper are as follows First the eta -NE region achieved with feedback is larger than or equal to the eta -NE region without feedback More importantly for each rate pair achievable at an eta -NE without feedback there exists at least one rate pair achievable at an eta -NE with feedback that is weakly Pareto superior Second there always exists an eta -NE transmit receive configuration that achieves a rate pair that is at most 1 bit s Hz per user away from the outer bound of the capacity_region
A design_and_control Environment for Internet-Based Telerobotics
This paper describes an environment for the design simulation and control of Internet-based force-reflecting telerobotic_systems We define these systems as using a segment of the computer_network to connect the master to the slave computer_networks introduce a time_delay that is best described by a time-varying random process Thus known techniques for controlling time-delay telerobots are not directly applicable and an environment for iterative designing and testing is necessary The underlying software_architecture sup ports tools for modeling the delay of the computer_network design ing a stable controller simulating the performance of a telerobotic system and testing the control algorithms using a force-reflecting input device Furthermore this setup provides data about including the Internet into more general telerobotic control architectures To demonstrate the features of this environment the complete proce dure for the design of a telerobotic controller is discussed First the delay pa
No-flow underfill flip chip assembly--an experimental and modeling analysis
In the flip-chip assembly process no-flow underfill materials have a particular advantage over traditional underfill the application and curing of the former can be undertaken before and during the reflow process This advantage can be exploited to increase the flip-chip manufacturing throughput However adopting a no-flow underfill process may introduce reliability issues such as underfill entrapment delamination at interfaces between underfill and other materials and lower solder joint fatigue life This paper presents an analysis on the assembly and the reliability of flip-chips with no-flow underfill The methodology adopted in the work is a combination of experimental and computer-modeling methods Two types of no-flow underfill materials have been used for the flip chips The samples have been inspected with X-ray and scanning acoustic microscope inspection systems to find voids and other defects Eleven samples for each type of underfill material have been subjected to thermal shock test and the number of cycles to failure for these flip chips have been found In the computer modeling part of the work a comprehensive parametric study has provided details on the relationship between the material properties and reliability and on how underfill entrapment may affect the thermal mechanical fatigue life of flip chips with no-flow underfill
Reflections on designing networked exertion games
Research in human-computer_interaction has begun to acknowledge the benefits of physicality in the way people interact with computers However the role of physicality is often understood in terms of the characteristics of physical smart_objects and their digital augmentation We are stressing that the physicality lies within the interaction not the object and use a subset of bodily actions exertion interactions as an example to demonstrate our point Emerging game_designs have shown that supporting such exertion interactions can enable beneficial experiences between geographically distant participants Based on several designs from our own work as well as others in this area we articulate reflections for the design of systems that support and facilitate bodily aspects of physicality in networked environments We believe our work can serve as guidance for designers who are interested in creating future systems that support networked exertion interactions
Stack-free process-oriented simulation
The process interaction world view is widely used in the general simulation community for its expressive power and is supported by most modern simulation languages In parallel discrete event simulation however its use remains comparatively rare due to the perceived inefficiency and difficulty of parallel_implementations We present a new implementation strategy for parallel process-oriented simulation languages This innovative semantics-based approach directly addresses two common concerns of such languages By concentrating on the intrinsic threads of control we avoid the proliferation of simulation objects and their associated costs that might result from a naive translation More fundamentally the primary costs associated with process-oriented languages -- those of context switching between stacks and in an optimistic setting of saving the state of these stacks -- are entirely eliminated since our explicit use of continuations avoids the need for stacks in the first place We similarly obtain cheap and natural thread preemption
network_congestion_control with Markovian multipath_routing
In this paper we consider an integrated model for TCP IP protocols with multipath_routing The model combines a network_utility_maximization for rate_control based on end-to-end queuing_delays with a Markovian Traffic Equilibrium for routing based on total expected delays We prove the existence of a unique equilibrium state which is characterized as the solution of an unconstrained strictly convex program A distributed_algorithm for solving this optimization problem is proposed with a brief discussion of how it can be implemented by adapting the current internet_protocols
Motion compensated lossy-to-lossless_compression of 4-D medical_images using integer wavelet_transforms
This paper proposes a method for progressive lossy-to-lossless_compression of four-dimensional 4-D medical_images sequences of volumetric images over time by using a combination of three-dimensional 3-D integer wavelet_transform IWT and 3-D motion_compensation A 3-D extension of the set-partitioning in hierarchical trees SPIHT algorithm is employed for coding the wavelet_coefficients To effectively exploit the redundancy between consecutive 3-D images the concepts of key and residual frames from video_coding is used A fast 3-D cube matching_algorithm is employed to do motion_estimation The key and the residual volumes are then coded using 3-D IWT and the modified 3-D SPIHT The experimental results presented in this paper show that our proposed compression_scheme achieves better lossy and lossless_compression_performance on 4-D medical_images when compared with JPEG-2000 and volumetric compression based on 3-D SPIHT
A multiuser receiver for code_division_multiple_access communications over multipath_channels
A multiuser communication system is considered where K users share a channel with multipath_propagation by using code division for multiple_access Data modulation is carried out by binary_phase_shift_keying and direct_sequence_spread_spectrum signaling The micro-cellular communication media is modeled as a frequency_selective_fading_channel with multipath_propagation The multipath diversity of the received_signals from the K users is exploited by a bank of K RAKE correlators Algorithms based on the maximum_likelihood rule have been developed for estimating the complex channel_coefficients as well as for detection of the desired data_packets from the sufficient statistics provided by the RAKE correlators The performance of the resulting multiuser detector is evaluated analytically and via Monte Carlo simulations The results indicate that the estimator of the channel_coefficients has a variance close to the cramer-rao_lower_bound and that the proposed multiuser detector is capable of eliminating the near-far effect as well as processing the signals propagated through multiple_paths
Spatial Synchronization Using Watermark Key Structure
Recently we proposed a method for constructing a template for efficient temporal synchronization in video_watermarking 1 Our temporal synchronization method uses a state machine key generator for producing the watermark embedded in successive frames of video A feature extractor allows the watermark key schedule to be content dependent increasing the difficulty of copy and ownership attacks It was shown that efficient synchronization can be achieved by adding temporal redundancy into the key schedule In this paper we explore and extend the concepts of our temporal synchronization method to spatial synchronization The key generator is used to construct the embedded watermark of non-overlapping blocks of the video creating a tiled structure 2 4 The autocorrelation of the tiled watermark contains local maxima or peaks with a grid-like structure where the distance between the peaks indicates the scale of the watermark and the orientation of the peaks indicate the watermark rotation Experimental results are obtained using digital_image watermarks Scaling and rotation attacks are investigated
SDG model-based analysis of fault propagation in control_systems
In the area of fault analysis SDG Signed directed_graph models can be used to describe the system states and the fault propagation paths which are the composition of qualitative deviation from the normal state In control_systems besides the natural relations caused by the physical properties the forced control actions determine the dynamic properties of the systems which cause the particularity of SDG model-based analysis In this paper the SDG description and the analysis methods of fault propagation in control_systems are presented and the typical cases like pid_control feedforward_control split-range control cascade control etc are illustrated A graphical analysis method is proposed to substitute the algebraic methods based on equations These results can be expanded to various control_systems and even be applied to large-scale industrial systems by the combination and connection of several basic elements
The distribution of citations from nation to nation on a field by field basis A computer calculation of the parameters
Following the methodology established byPrice this paper analyzes the empirical evidence of citation matrices Using the data cleaned and tabulated by Computer Horizons Inc from the Science Citation Index data banks it is shown that the non-diagonal elements of the square citation matrices can be accounted for very satisfactorily by assigning each nation a characteristic output and input coefficient in each field measured the ratio of these coefficients provides a measure of quality Deviations from this simple model give measures of particular linkage strengths between nations showing some evidence of preferences and avoidances that exist for reason of language social structure etc It is also shown that the diagonal data can be accounted for by the measurable phenomenon that each nation seems to publish partly for the international knowledge system and party for its own domestic purposes Thus three parameters and a cluster map can parsimoniously describe the citation data within the limits of random error
An approach to object-oriented discrete-event simulation of manufacturing systems
It is shown how the object-oriented approach can be applied to discrete-event simulation and in particular to discrete-event simulation of manufacturing systems A hierarchical_structure of object classes is proposed consisting of three class libraries base classes simulation support object classes and manufacturing systems simulation object classes The definition of each class and how the class objects interact with one another are discussed An example of a discrete-event simulation model developed using the object classes is presented The example illustrates the basic nature merits and drawbacks of this approach
Free subcarrier optimization for peak-to-average power ratio minimization in ofdm_systems
Peak-to-average power ratio PAR reduction techniques are often employed to increase the power efficiency of orthogonal_frequency_division_multiplexing ofdm_systems A recently proposed PAR optimization_method demonstrates how the PAR can be minimized when free subcarriers and a certain distortion allowance on the error_vector_magnitude EVM are available In this paper we derive the lower bound on the capacity for such a system and investigate the capacity- maximizing number of free subcarriers that should be used
A spatial mapping algorithm for heterogeneous coarse-grained reconfigurable_architectures
In this work we investigate the problem of automatically mapping applications onto a coarse-grained reconfigurable_architecture and propose an efficient_algorithm to solve the problem We formalize the mapping problem and show that it is NP-complete To solve the problem within a reasonable amount of time we divide it into three subproblems covering partitioning and layout Our empirical results demonstrate that our technique produces nearly as good performance as hand-optimized outputs for many kernels
Market equilibrium via a primal--dual algorithm for a convex program
We give the first polynomial_time_algorithm for exactly computing an equilibrium for the linear utilities case of the market model defined by Fisher Our algorithm uses the primal--dual paradigm in the enhanced setting of KKT conditions and convex programs We pinpoint the added difficulty raised by this setting and the manner in which our algorithm circumvents it
Enhancement of an optical_fiber_sensor source_separation Based on Brillouin Spectrum
Distributed optical_fiber_sensors have gained an increasingly prominent role in structural-health monitoring These are composed of an optical_fiber cable in which a light impulse is launched by an opto-electronic device The scattered light is of interest in the spectral domain the spontaneous Brillouin spectrum is centered on the Brillouin frequency which is related to the local strain and temperature changes in the optical_fiber When coupled with an industrial Brillouin optical time-domain analyzer B-OTDA an optical_fiber cable can provide distributed measurements of strain and or temperature with a spatial resolution over kilometers of 40 cm This paper focuses on the functioning of a B-OTDA device where we address the problem of the improvement of spatial resolution We model a Brillouin spectrum measured within an integration base of 1 m as the superposition of the elementary spectra contained in the base Then the spectral distortion phenomenon can be mathematically explained if the strain is not constant within the integration base the Brillouin spectrum is composed of several elementary spectra that are centered on different local Brillouin frequencies We propose a source_separation methodology approach to decompose a measured Brillouin spectrum into its spectral components The local Brillouin frequencies and amplitudes are related to a portion of the integration base where the strain is constant A layout algorithm allows the estimation of a strain profile with new spatial resolution chosen by the user Numerical tests enable the finding of the optimal parameters which provides a reduction to 1 cm of the 40-cm spatial resolution of the B-OTDA device These parameters are highlighted during a comparison with a reference strain profile acquired by a 5-cm-resolution Rayleigh scatter analyzer under controlled conditions In comparison with the B-OTDA strain profile our estimated strain profile has better accuracy with centimeter spatial resolution
Intra dynamic scenario relations and a dynamic decision making algorithm
In this paper we present the composition of a general dynamic scenario the relations of its components and a dynamic making algorithm called ECA Evaluation and Correction Algorithm The paper proposes three relations namely stable relation controllable relation and uncontrollable relation numerical_results are given by some simple dynamic scenarios
PGMRA a web_server for phenotype genotype many-to-many relation analysis in GWAS
It has been proposed that single_nucleotide_polymorphisms SNPs discovered by genome-wide association studies GWAS account for only a small fraction of the genetic_variation of complex traits in human population The remaining unexplained variance or missing heritability is thought to be due to marginal effects of many loci with small effects and has eluded attempts to identify its sources Combination of different studies appears to resolve in part this problem However neither individual GWAS nor meta-analytic combinations thereof are helpful for disclosing which genetic variants contribute to explain a particular phenotype Here we propose that most of the missing heritability is latent in the GWAS data which conceals intermediate phenotypes To uncover such latent information we propose the PGMRA server that introduces phenomics the full set of phenotype features of an individual to identify SNP-set structures in a broader sense i e causally cohesive genotype phenotype relations These relations are agnostically identified without considering disease status of the subjects and organized in an interpretable fashion Then by incorporating a posteriori the subject status within each relation we can establish the risk surface of a disease in an unbiased mode This approach complements instead of replaces current analysis methods The server is publically available at http phop ugr es fenogeno
Parallel Lanczos bidiagonalization for total least squares filter in robot_navigation
In the robot_navigation problem noisy sensor_data must be filtered to obtain the best estimate of the robot position The discrete kalman_filter which usually is used for prediction and detection of signals in communication and control_problems has become a commonly used method to reduce the effect of uncertainty from the sensor_data However due to the special domain of robot_navigation the Kalman approach is very limited The use of total least squares filter has been proposed Boley and Sutherland 1993 which is capable of converging with many fewer readings and achieving greater accuracy than the classical kalman_filter The main disadvantage of those approaches is that they can not deal with the case where the noise_subspace is of dimension higher than one Here a parallel krylov_subspace_method on parallel distributed_memory computers which uses the Lanczos bidiagonalization process with updating techniques is proposed which is more computationally attractive to solve the total least squares problems The parallel_algorithm is derived such that all inner products of a single iteration step are independent Therefore the cost of global communication which represents the bottleneck of the parallel_performance on parallel distributed_memory computers can be significantly reduced This filter is very promising for very large data information and from our very preliminary experiments we can obtain more precise accuracy and better speedup
Bit and power loading for the multiband impulse_radio UWB architecture
In this paper we present two different bit and power loading algorithms for the non-coherent multiband impulse UWB architecture The first one is a very simple threshold based bit loading algorithm and an extension of the detect and avoid DAA algorithm presented in 1 The second one is a more powerful algorithm enabling also power loading These algorithms allow a more efficient and flexible spectrum use higher data rates and use less transmission_power The bit_error_rate_performance is significantly improved Both algorithms support inherent powerful DAA
Intelligent decision system and its application in business innovation self assessment
In this paper it is described how a multiple criteria decision_analysis software tool the Intelligent Decision System IDS can be used to help business self-assessment Following a brief outline of a model for assessing business innovation capability and the IDS software the process of using IDS to implement different types of assessment questions is discussed It is demonstrated that IDS is a flexible tool capable of handling different types of data in self-assessment including uncertain and incomplete data and providing a wide range of information including scores performance diversity strength and weakness profile and graphics
Cold delay defect screening
Delay defects can escape detection during the normal production test flow particularly if they do not affect any of the long paths included in the test flow Some delay defects can have their delay increased making them easier to detect by carrying out the test with a very low supply voltage VLV testing However VLV testing is not effective for delay defects caused by high resistance interconnects This paper presents a screening technique for such defects This technique cold testing relies on carrying out the test at low temperature One particular type of defect silicide open is analyzed and experimental data are presented to demonstrate the effectiveness of cold testing
knowledge_representation for conceptual simulation modeling
Simulation is a powerful tool that helps decision makers in business and industry to solve difficult and complex problems reduce cost improve quality and productivity and shorten time-to-market However the technology is still underutilized in many applications due to several reasons In this study we address these issues using a knowledge_engineering approach i e develop efficient and robust models and formats to capture represent and organize the knowledge for developing conceptual simulation models that can be generalized and interfaced with different applications and implementation tools The research fits into a larger project effort that aims to create a sustained research program on knowledge-based simulation
An application-level implementation of causal timestamps and causal ordering
Maintenance of causality information in distributed_systems has previously been implemented in the communications infrastructure with the focus on providing reliability and availability for distributed services While this approach has a number of advantages moving causality information up into the view and control of the application programmer is useful and in some cases preferable In an experiment at the University of Queensland libraries to support application-level maintenance of causality information have been implemented The libraries allow the collection and use of causality information under programmer control supplying a basis for making causal dependency information available for application management and troubleshooting The libraries are also unique in supporting existing distributed_systems based on the remote procedure call paradigm This paper describes the underlying theory of causality and the design and implementation of the libraries An event reporting service example is used to motivate the approach and a number of previously unresolved practical problems are addressed in the design process
A high-quality multirate real-time CELP coder
The design and implementation of a real-time CELP coder for mobile_communication applications are discussed To realize a single-chip implementation several tradeoffs were made without compromising speech_quality In addition techniques that make the coder more robust under a variety of channel_conditions are discussed The real-time coder can be operated at different bit_rates 8 6 8 4 6 kb s by simply changing the frame update rates The speech_quality was evaluated through a formal listening test and it was found that this coder compares favorably with other standardized coders operating at similar or higher rates
Weighted least squares training of support_vector classifiers leading to compact and adaptive schemes
An iterative block training method for support_vector classifiers SVCs based on weighted least squares WLS optimization is presented The algorithm which minimizes structural risk in the primal space is applicable to both linear and nonlinear machines In some nonlinear cases it is necessary to previously find a projection of data onto an intermediate-dimensional space by means of either principal_component_analysis or clustering_techniques The proposed approach yields very compact machines the complexity reduction with respect to the SVC solution is especially notable in problems with highly overlapped classes Furthermore the formulation in terms of WLS minimization makes the development of adaptive SVCs straightforward opening up new fields of application for this type of model mainly online processing of large amounts of static stationary data as well as online update in nonstationary scenarios adaptive solutions The performance of this new type of algorithm is analyzed by means of several simulations
A distributed parallel approach for BGP routing_table partitioning in next generation routers
The rapid growth of routing_tables represents a major challenge facing the scalability of BGP and indeed the whole Internet infrastructure In this paper we introduce a novel distributed_algorithmic scheme for partitioning the BGP routing_table on multiple controller cards where we exploit parallelism to enhance both the lookup speed and the scalability of the RIB routing_information Base The proposed scheme increases the lookup performance by letting unrelated tasks such as the Best Match Prefix BMP lookup and the BGP decision process to be executed in parallel at different controller cards Simulations show that our proposal outperforms classical central lookup mechanisms with a reasonably acceptable cost while it increases considerably the space scalability of the BGP routing_table
Fast committee machines for regression and classification
In many data_mining_applications we are given a set of training examples and asked to construct a regression machine or a classifier that has low prediction error or low error rate on new examples respectively An important issue is speed especially when there are large amounts of data We show how both classification and prediction error can be reduced by using boosting techniques to implement committee machines In our implementation of committees using either classification trees or regression trees we show how we can trade off speed against either error rate or prediction error
maximum-likelihood_detection of nonlinearly distorted multicarrier symbols by iterative_decoding
This paper proposes a new method for decoding multicarrier symbols with severe nonlinear distortion The first part evaluates mutual_information expressions for practical nonlinear_models and shows the performance bounds for commonly used receiver structures Then we derive the maximum-likelihood ML sequence estimator which unfortunately has an exponential complexity due to the nonlinear distortion This extremely large complexity can be reduced with a simple algorithm that iteratively estimates the nonlinear distortion thereby reducing the exponential ML to the standard ML without nonlinear distortion The proposed method can be used to reduce the peak-to-average power ratio of multicarrier signals by clipping the transmit sequence It can also be used to correct any nonlinear distortion present in transmitter receiver amplifiers that are operating close to saturation
Pricing Longevity Bonds Based on Stochastic Mortality Forecasting by Panel Data Procedures
In order to hedge the longevity risk longevity bonds are designed whose payoff structure depends on the changes in mortality To forecast the mortality more precisely we use a time-dynamic stochastic_model by utilizing a panel data approach to forecast the mortality rates and get a survival index Empirical study is conducted with the data in China Then we apply these forecasting mortality rates to evaluate one kind of longevity bond It turns out that it is reliable for the social security_systems and the life insurance industry
Partitions and Edge Colourings of Multigraphs
Erdős and Lovasz conjectured in 1968 that for every graph_g with chi G omega G and any two integers s t geq 2 with s t chi G 1 there is a partition S T of the vertex_set V G such that chi G S geq s and chi G T geq t Except for a few cases this conjecture is still unsolved In this note we prove the conjecture for line graphs of multigraphs
Robust adaptive_fuzzy_sliding_mode_control for a Class of uncertain_nonlinear_systems with Unknown Dead-Zone
In this paper a robust adaptive_fuzzy_sliding_mode_control scheme is presented for a class of uncertain_nonlinear_systems preceded by an unknown dead-zone Dead-zone characteristics are quite commonly encountered in actuators such as hydraulic and pneumatic valves electric servomotors and electronic circuits etc Therefore by using a description of a dead-zone and exploring the properties of this dead-zone model intuitively and mathematically a robust adaptive_fuzzy sliding control method is presented without constructing the dead-zone inverse The unknown nonlinear_functions of the plant are approximated by the fuzzy_logic_system according to some adaptive_laws Based on lyapunov_stability_theorem and the theory of variable_structure_control the proposed robust adaptive_fuzzy_sliding_mode_control scheme can guarantee the robust_stability of the whole closed-loop system with an unknown dead-zone in the actuator and obtain good tracking_performance as well Finally an example and simulation results are provided to illustrate the effectiveness of the proposed method
Tracer kinetic modeling by morales-smith hypothesis in hepatic perfusion CT
Most of the existing tracer kinetic models for dynamic contrast-enhanced CT or MRI do not fully describe the principles of intra- and transcapillary transport of tracers One point is to disregard the concentration profiles between the inlets and outlets of capillaries which may cause a biased estimation of tissue parameters by a systematic error The Morales-Smith hypothesis enables one to resolve this ambiguity by assuming that the difference between arterial and venous concentrations is proportional to the difference between the arterial and capillary concentrations If the backflow of administered tracer into the plasma compartment is negligible compared to its outflow into the interstitial compartment during the initial enhancement phase after tracer administration the capillary concentration can be considered to fall exponentially along the capillary from the arterial concentration to the venous concentration by the Renkin-Crone model i e unidirectional extraction fraction which can be incorporated in the concept of the Morales-Smith hypothesis In this study we reformed the mass-balance equations and mathematical solutions of several representative and well-known tracer kinetic models so that the Morales-Smith hypothesis could be incorporated into their compartment tracer kinetics considering a tissue-specific factor independent of time as proposed by Brix et al 5 The tissue-specific factor was applied to a liver tumor case study in perfusion CT to illustrate the potential effectiveness of the Morales-Smith hypothesis The proposed scheme was shown to be potentially useful for more consistent and reliable estimation of physiologic tissue parameters
Algorithm for decomposing an analytic_signal into AM and positive FM components
An analytic_signal permits unambiguous characterization of the phase and envelope of a real signal But the analytic_signal s phase-derivative i e the instantaneous_frequency IF is typically a wild function and can take on values ranging from negative infinity to positive infinity Fortunately any analytic_signal can be decomposed into a minimum phase MinP signal component and an all-phase AllP signal component While the MinP signal s log-envelope and its phase form a hilbert_transform pair the AllP signal has a positive definite instantaneous_frequency PIF unlike that of the original analytic_signal We propose an elegant computational algorithm that separates the MinP and AllP components of the analytic_signal The envelope of the MinP component corresponds to the AM and the PIF of the AllP component corresponds to the positive FM
Processing nested complex sequence pattern queries over event streams
Complex event processing CEP has become increasingly important for tracking and monitoring applications ranging from health care supply chain management to surveillance These monitoring applications submit complex event queries to track sequences of events that match a given pattern As these systems mature the need for increasingly complex nested sequence queries arises while the state-of-the-art CEP systems mostly focus on the execution of flat sequence queries only In this paper we now introduce an iterative execution strategy for nested CEP queries composed of sequence negation AND and OR operators Lastly we have introduced the promising direction of applying selective caching of intermediate results to optimize the execution Our experimental study using real-world stock trades evaluates the performance of our proposed iterative execution strategy for different query types
Learning Top-Down Grouping of Compositional Hierarchies for Recognition
The complexity of real world image categorization and scene analysis requires compositional strategies for object representation This contribution establishes a compositional hierarchy by first performing a perceptual bottom-up grouping of edge pixels to generate salient contour curves A subsequent recursive top-down grouping yields a hierarchy of compositions All entities in the compositional hierarchy are incorporated in a bayesian_network that couples them together by means of a shape model The probabilistic_model underlying top-down grouping as well as the shape model is learned automatically from a set of training images for the given categories As a consequence compositionality simplifies the learning of complex category models by building them from simple frequently used compositions The architecture is evaluated on the highly challenging Caltech 101 database1 which exhibits large intra-category variations The proposed compositional approach shows competitive retrieval rates in the range of 53 0 0 49
On the energy-efficiency of speculative hardware
Microprocessor trends are moving towards wider architectures and more aggressive speculation With the increasing transistor budgets energy consumption has become a critical design constraint To address this problem several researchers have proposed and evaluated energy-efficient variants of speculation mechanisms However such hardware is typically evaluated in isolation and its impact on the energy consumption of the rest of the processor for example due to wrong-path executions is ignored Moreover the available metrics that would provide a thorough evaluation of an architectural optimization employ somewhat complicated formulas with hard-to-measure parametersIn this paper we introduce a simple method to accurately compare the energy-efficiency of speculative architectures Our metric is based on runtime analysis of the entire processor chip and thus captures the energy consumption due to the positive as well as the negative activities that arise from the speculation activities We demonstrate the usefulness of our metric on the example of value speculation where we found some proposed value predictors including low-power_designs not to be energy-efficient
A new clutter rejection algorithm for Doppler ultrasound
Several strategies known as clutter or wall Doppler filtering were proposed to remove the strong echoes produced by stationary or slow moving tissue structures from the Doppler blood flow signal In this study the matching pursuit MP method is proposed to remove clutter components The MP method decomposes the Doppler signal into wavelet atoms that are selected in a decreasing energy order Thus the high-energy clutter components are extracted first In the present study the pulsatile Doppler signal s n was simulated by a sum of random-phase sinusoids Two types of high-amplitude clutter signals were then superimposed on s n time-varying low-frequency components covering systole and early diastole and short transient clutter signals distributed within the whole cardiac cycle The Doppler signals were modeled with the MP method and the most dominant atoms were subtracted from the time-domain signal s n until the signal-to-clutter S C ratio reached a maximum For the low-frequency clutter signal the improvement in S C ratio was 19 0 spl plusmn 0 6 dB and 72 0 spl plusmn 4 5 atoms were required to reach this performance For the transient clutter signal ten atoms were required and the maximum improvement in S C ratio was 5 5 spl plusmn 0 5 dB The performance of the MP method was also tested on real data recorded over the common carotid artery of a normal subject Removing 15 atoms significantly improved the appearance of the Doppler sonogram contaminated with low-frequency clutter Many more atoms over 200 were required to remove transient clutter components These results suggest the possibility of using this signal_processing approach to implement clutter rejection filters on ultrasound commercial instruments
Causal time series analysis of functional magnetic resonance imaging data
This review focuses on dynamic causal analysis of functional magnetic resonance fMRI data to infer brain connectivity from a time series analysis and dynamical systems perspective Causal influence is expressed in the Wiener-Akaike-Granger-Schweder WAGS tradition and dynamical systems are treated in a state_space_modeling framework The nature of the fMRI signal is reviewed with emphasis on the involved neuronal physiological and physical processes and their modeling as dynamical systems In this context two streams of development in modeling causal brain connectivity using fMRI are discussed time series approaches to causality in a discrete_time tradition and dynamic systems and control_theory approaches in a continuous_time tradition This review closes with discussion of ongoing work and future perspectives on the integration of the two approaches
medium_access_control in ad_hoc_networks with MIMO links optimization considerations and algorithms
we present a medium_access_control mac_protocol for ad_hoc_networks with multiple_input_multiple_output MIMO links MIMO links provide extremely high spectral_efficiencies in multipath_channels by simultaneously transmitting multiple independent data_streams in the same channel mac_protocols have been proposed in related work for ad_hoc_networks with other classes of smart_antennas such as switched beam antennas However as we substantiate in the paper the unique characteristics of MIMO links coupled with several key optimization considerations necessitate an entirely new mac_protocol We identify several advantages of MIMO links and discuss key optimization considerations that can help in realizing an effective mac_protocol for such an environment We present a centralized algorithm called stream-controlled medium_access SCMA that has the key optimization considerations incorporated in its design Finally we present a distributed SCMA protocol that approximates the centralized algorithm and compare its performance against that of baseline protocols that are CSMA CA variants
Design and Implementation of physical_layer private_key Setting for wireless_networks
Due to the enormous spreading of applied wireless_networks security is actually one of the most important issues for telecommunications One of the main issue in the field of securing wireless information exchanging is the initial common knowledge between source and destination A shared secret is normally mandatory in order to decide the encryption_algorithm or code or key of the information stream It is usual to exchange this common a priori knowledge by using a secure channel Now a days a secure wireless_channel is not possible In fact normally the common a priori knowledge is already established but this is not secure or by using a non-radio_channel that implies a waste of time and resource This contribution deals with the proposal of a new modulation technique ensuring secure communication in a full wireless environment The information is modulated at physical_layer by the thermal noise experienced by the link between two terminals A loop scheme is designed for unique recovering of mutual_information The probability of error detection is analytically derived for the legal users and for the third unwanted listener The proposed scheme has also been implemented in a Xilinx Virtex II FPGA R N R N All the results show that the performance of the proposed scheme yields the advantage of intrinsic security i e the mutual_information cannot be physically demodulated passive attack or denied active attack by a third terminal leading us to conclude that the proposed technique is really useful for private_key_distribution in every wireless_network
Circular Acoustic Vector-Sensor Array for Mode Beamforming
Undersea warfare relies heavily on acoustic means to detect a submerged vessel The frequency of the acoustic_signal radiated by the vessel is typically very low thus requires a large array aperture to achieve acceptable angular resolution In this paper we present a novel approach for low-frequency direction-of-arrival DOA estimation using miniature circular vector-sensor array mounted on the perimeter of a cylinder Under this approach we conduct beamforming using decomposition in the acoustic mode domain rather than frequency_domain to avoid the long wavelength constraints We first introduce a multi-layer acoustic gradient scattering model to provide a guideline and performance predication tool for the mode beamformer design and algorithm We optimize the array_gain and frequency response with this model We further develop the adaptive DOA estimation algorithm based on this model We formulate the Capon spectra of the mode beamformer which is independent of the frequency band after the mode decomposition Numerical simulations are conducted to quantify the performance and evaluate the theoretical_results developed in this study
On the expressive power of KLAIM-based calculi
We study the expressive power of variants of KLAIM an experimental language with programming primitives for network-aware programming that combines the process algebra approach with the coordination-oriented one KLAIM has proved to be suitable for programming a wide range of distributed_applications with agents and code mobility and has been implemented on the top of a runtime_system written in Java In this paper the expressivity of its constructs is tested by distilling from it a few more and more foundational languages and by studying the encoding of each of them into a simpler one The expressive power of the considered calculi is finally tested by comparing one of them with asynchronous π-calculus
Fast principal_component_analysis using Eigenspace Merging
In this paper we propose a fast algorithm for principal_component_analysis PCA dealing with large high-dimensional_data sets A large data set is firstly divided into several small data sets Then the traditional pca_method is applied on each small data set and several eigenspace models are obtained where each eigenspace model is computed from a small data set At last these eigenspace models are merged into one eigenspace model which contains the PCA result of the original data set Experiments on the FERET data set show that this algorithm is much faster than the traditional pca_method while the principal_components and the reconstruction errors are almost the same as that given by the traditional method
Towards the Automated Generation of Hard Disk Models through Physical Geometry Discovery
As the High Performance Computing industry moves towards the exascale era of computing parallel scientific and engineering applications are becoming increasingly complex The use of simulation allows us to predict how an application s performance will change with the adoption of new hardware or software helping to inform procurement decisions In this paper we present a disk simulator designed to predict the performance of read and write_operations to a single hard disk drive HDD Our simulator uses a geometry discovery benchmark Diskovery in order to estimate the data layout of the HDD as well as the time spent moving the read write head We validate our simulator against two different HDDs using a benchmark designed to simulate common disk read and write patterns demonstrating accuracy to within 5 of the observed I O time for sequential operations and to within 10 of the observed time for seek-heavy workloads
A Novel Approach for Binarization of Overlay Text
In this paper we presents a new binarization approach to extract text pixels from complex background in video frames The binarization computation is a crucial step for video text_recognition which can greatly increase the recognition accuracy of an OCR software The proposed approach consists of four phases First the text polarity is determined i e light text with dark background or dark text with light background Then the pixels in the given image are clustered into K clusters using the k-means_algorithm in the rgb_color_space and the text cluster is selected based on the text polarity Further the MRF Model is exploited to get the binarization result Finally the result is further refined by the Log-gabor_filter The Experimental results on a large dataset show that the significant gains have been obtained according to the segmentation_performance on the pixel level as well as the OCR accuracy
An efficient_architecture for JPEG2000 coprocessor
JPEG2000 is a new international standard for still image_compression It provides various functions in one single coding stream and the better compression quality than the traditional JPEG especially in the high_compression_ratio However the heavy computation and large internal memory requirement still restrict the consumer electronics applications In this paper we propose a QCB quad code block -based DWT method to achieve the higher parallelism than the traditional DWT approach of JPEG2000 coding process Based on the QCB-based DWT engine three code blocks can be completely generated after every fixed time slice recursively Thus the DWT and EBCOT processors can process simultaneously and the high computational EBCOT then has the higher parallelism of the JPEG2000 encoding system By changing the output timing of the DWT process and parallelizing with EBCOT the internal tile memory size can be reduced by a factor of 4 The memory_access cycles between the internal tile memory and the code block memory also decrease with the smooth encoding flow
Predicting Billboard Success Using Data-Mining in p2p_networks
peer_to_peer_networks are the leading cause for music piracy but also used for music sampling prior to purchase In this paper we investigate the relations between music file_sharing and sales both physical and digital using large Peer-to-Peer query database information We compare file_sharing_information on songs to their popularity on the Billboard Hot 100 and the Billboard Digital Songs charts and show that popularity trends of songs on the Billboard have very strong correlation 0 88-0 89 to their popularity on a peer-to-peer_network We then show how this correlation can be utilized by common data_mining_algorithms to predict a song s success in the Billboard in advance using Peer-to-Peer information
Effects of Popular Exemplars in Television News
Common people that are apparently randomly selected by journalists to illustrate a news story popular exemplars have a substantial effect on what the audience think about the issue This effect may be partly due to the mere fact that popular exemplars attract attention and act as attention commanders just like many other speaking sources in the news Yet popular exemplars effects extend well beyond that of other talking sources Due to their similarity trustworthiness and the vividness of their account popular exemplars have significantly more impact than experts that are being interviewed or in particular than politicians that are quoted in the news We show this drawing on an internet-based experiment that uses fake television news items as stimuli and that systematically compares the effect of these talking sources in the news We also find that taking into account preexisting attitudes changes the findings substantially The effects are more robust and yield a more nuanced picture of what typ
On second-order_statistics of log-periodogram with correlated components
We derive an explicit expression for the covariance of the log-periodogram power spectral density estimator for a zero mean gaussian_process We do not make the assumption that the spectral components of the process are uncorrelated Applications to spectral estimation and to cepstral modeling in automatic_speech_recognition are discussed
An additive exponential noise channel with a transmission deadline
We derive the maximum_mutual_information for an additive exponential noise AEN channel with a peak input constraint We find that the optimizing input density is mixed with singularities similar to previous results for AEN channels with a mean input constraint Likewise the maximum_mutual_information takes a similar form though obviously the maximum for the peak constraint is smaller than for the corresponding mean-constrained channel This model is inspired by multiple biological phenomena and processes which can be abstracted as follows inscribed matter is sent by an emitter moves through a medium and arrives eventually at its destination receptor The inscribed matter can convey information in a variety of ways such as the number of signaling quanta - molecules macromolecular complexes organelles cells and tissues - that are emitted as well as the detailed pattern of their release However rather than focus on a general class of emitter-receptor systems or a particular exemplar of biomedical importance our ultimate goal is to provide bounds on the potential efficacy of timed-release signaling for any system which emits identical signaling quanta That is we seek to apply one of the most potent aspects of information_theory to biological signaling - mechanism blindness - in the hopes of gaining insights applicable to diverse systems that span a wide range of spatiotemporal scales
Exhaustive search for small fully absorbing sets and the corresponding low error-floor decoder
This work provides an exhaustive search algorithm for finding small fully absorbing sets FASs of arbitrary low-density parity-check ldpc_codes In particular given any ldpc_code the problem of finding all FASs of size less than t is formulated as an integer programming problem for which a new branch- -bound algorithm is devised New node selection and the tree-trimming mechanisms are designed to further enhance the efficiency of the algorithm The proposed algorithm is capable of finding all FASs of size 11 with no larger than 2 induced odd-degree check_nodes for ldpc_codes of length 1000 The resulting exhaustive list of small FASs is then used to devise a new post-processing decoder numerical_results show that by taking advantage of the exhaustive list of small FASs the proposed decoder significantly lowers the error_floor for codes of practical lengths and outperforms the state-of-the-art low-error-floor decoders
A multi-objective artificial immune algorithm for parameter optimization in support_vector_machine
support_vector_machine SVM is a classification method based on the structured risk minimization principle Penalize C and kernel s parameters of SVM must be carefully selected in establishing an efficient svm_model These parameters are selected by trial and error or man s experience Artificial immune system AIS can be defined as a soft_computing method inspired by theoretical immune system in order to solve science and engineering problems A multi-objective artificial immune algorithm has been used to optimize the kernel and penalize parameters of SVM in this paper In training stage of SVM multiple solutions are found by using multi-objective artificial immune algorithm and then these parameters are evaluated in test stage The proposed algorithm is applied to fault diagnosis of induction motors and anomaly_detection_problems and successful results are obtained
A novel hidden station detection mechanism in IEEE 802 11 WLAN
The popular IEEE 802 11 wireless local area network WLAN is based on a carrier_sense_multiple_access_with_collision_avoidance CSMA CA where a station listens to the medium before transmission in order to avoid collision If there exist stations which can not hear each other i e hidden stations the potential collision probability increases thus dramatically degrading the network throughput The RTS CTS request-to-send clear-to-send frame exchange is a solution for the hidden station problem but the RTS CTS exchange itself consumes the network resources by transmitting the control frames In order to maximize the network throughput we need to use the RTS CTS exchange adaptively only when hidden stations exist in the network In this letter a simple but very effective hidden station detection mechanism is proposed Once a station detects the hidden stations via the proposed detection mechanism it can trigger the usage of the RTS CTS exchange The simulation results demonstrate that the proposed mechanism can provide the maximum system throughput performance
Low complexity algorithm for robust video frame_rate_up-conversion FRUC technique
Two challenging situations for video frame_rate_up-conversion FRUC are first identified and analyzed namely when the input video has abrupt illumination change and or a low frame rate Then a low-complexity processing technique and robust FRUC algorithm are proposed to address these two issues The proposed algorithm utilizes a translational motion_vector model of the first- and the second-order and detects the continuity of these motion_vectors Additionally in order to improve perceptual quality of interpolated frame spatial smoothness criterion is employed The superior performance of the proposed algorithm has been tested extensively and representative examples are given in this work
Timestamping schemes for MPEG-2 systems layer and their effect on receiver clock_recovery
We propose and analyze several strategies for performing timestamping of an MPEG-2 Transport Stream transmitted over a packet-switched network using the PCR-unaware encapsulation scheme and analyze their effect on the quality of the recovered clock at the MPEG-2 Systems decoder When the timestamping scheme is based on a timer with a fixed period the PCR values in the packet stream may switch polarity deterministically at a frequency determined by the timer period and the transport rate of the MPEG signal This in turn can degrade the duality of the recovered clock at the receiver beyond acceptable limits We consider three timestamping schemes for solving this problem 1 selecting a deterministic timer period to avoid the phase difference in PCR values altogether 2 fine-tuning the deterministic timer period to maximize the frequency of PCR polarity changes and 3 selecting the timer period randomly to eliminate the deterministic PCR polarity changes For the case of deterministic timer period we derive the frequency of the PCR polarity changes as a function of the timer period and the transport rate and use it to find ranges of the timer period for acceptable quality of the recovered clock We also analyze a random timestamping procedure based on a random telegraph process and obtain lower bounds on the rate of PCR polarity changes such that the recovered clock does not violate the PAL NTSC clock specifications The analytical_results are verified by simulations with both synthetic and actual MPEG-2 Transport Streams sent to a simulation model of an MPEG-2 Systems decoder
Pyramid transform and scale-space analysis in image_analysis
The pyramid transform compresses images while preserving global_features such as edges and segments The pyramid transform is efficiently used in optical_flow_computation starting from planar images captured by pinhole camera systems since the propagation of features from coarse sampling to fine sampling allows the computation of both large displacements in low-resolution images sampled by a coarse grid and small displacements in high-resolution images sampled by a fine grid R N R N The image pyramid transform involves the resizing of an image by downsampling after convolution with the gaussian_kernel Since the convolution with the gaussian_kernel for smoothing is derived as the solution of a linear diffusion_equation the pyramid transform is performed by applying a downsampling operation to the solution of the linear diffusion_equation
Adaptive modelling of digital hearing aids using a subband affine projection algorithm
Adaptive modeling of digital hearing aids is useful in characterizing the hearing aid behavior in response to real world stimuli such as speech and music Most modern hearing aids employ amplitude compression in different_frequency_bands for effective mapping of the wide_dynamic_range audio_signals into the reduced dynamic range of the hearing impaired_listeners Due to the presence of independent compression channels the conventional fullband adaptive model might not adequately characterize the performance of a multichannel compression hearing aid MCHA In this paper we propose a subband adaptive modeling approach to characterize the electroacoustic performance of a MCHA The proposed structure employs uniform oversampled DFT filterbanks for analysis and synthesis and the affine projection algorithm for adaptive modeling in each subband Experiments with simulated MCHAs showed that the subband structure outperforms the fullband structure under a variety of operating conditions
A Cost Effective Centralized adaptive_routing for Networks-on-Chip
As the number of applications and programmable units in CMPs and MPSoCs increases the Network-on-Chip NoC encounters unpredictable heterogeneous and time dependent traffic loads This motivates the introduction of adaptive_routing_mechanisms that balance the NoC s loads and achieve higher throughput compared with traditional oblivious routing_schemes An effective adaptive_routing_scheme should be based on a global view of the network state However most current adaptive_routing_schemes following off-chip_networks are based on distributed reactions to local congestion In this paper we leverage the unique on-chip capabilities and introduce a novel paradigm of NoC centralized adaptive_routing Our scheme continuously monitors the global traffic load in the network and modifies the routing of packets to improve load balancing accordingly We present a specific design for the case of mesh_topology where XY or YX routes are adaptively selected for each source-destination pair We show that while our implementation is lightweight and scalable in hardware costs it outperforms oblivious and distributed adaptive_routing_schemes in terms of load balancing and average packet_delay
Robust directional features for wordspotting in degraded Syriac manuscripts
This paper presents a contribution to word_spotting applied for digitized Syriac manuscripts The Syriac language was wrongfully accused of being a dead language and has been set aside by the domain of handwriting_recognition Yet it is a very fascinating handwriting that combines the word structure and calligraphy of the Arabic handwriting with the particularity of being intentionally written tilted by an angle of approximately 45deg For the spotting process we developed a method that should find all occurrences of a certain query word image based on a selective sliding window technique from which we extract directional features and afterwards perform a matching using Euclidean distance correspondence between features The proposed method does not require any prior_information and does not depend of a word to character_segmentation algorithm which would be extremely complex to realize due to the tilted nature of the handwriting
Statistical semantics for enhancing document_clustering
document_clustering_algorithms usually use vector_space_model VSM as their underlying model for document_representation VSM assumes that terms are independent and accordingly ignores any semantic_relations between them This results in mapping documents to a space where the proximity between document vectors does not reflect their true semantic_similarity This paper proposes new models for document_representation that capture semantic_similarity between documents based on measures of correlations between their terms The paper uses the proposed models to enhance the effectiveness of different algorithms for document_clustering The proposed representation models define a corpus-specific semantic_similarity by estimating measures of term term correlations from the documents to be clustered The corpus of documents accordingly defines a context in which semantic_similarity is calculated Experiments have been conducted on thirteen benchmark data sets to empirically evaluate the effectiveness of the proposed models and compare them to VSM and other well-known models for capturing semantic_similarity
Transcript mapping for historic handwritten_document_images
There is a large number of scanned historical_documents that need to be indexed for archival and retrieval purposes A visual word_spotting scheme that would serve these purposes is a challenging task even when the transcription of the document_image is available We propose a framework for mapping each word in the transcript to the associated word image in the document Coarse word mapping based on document constraints is used for lexicon reduction Then word mappings are refined using word recognition results by a dynamic programming algorithm that finds the best match while satisfying the constraints
Less Is More Mixed-Initiative Model-Predictive Control With Human Inputs
This paper presents a new method for injecting human inputs into mixed-initiative interactions between humans and robots The method is based on a model-predictive control MPC formulation which inevitably involves predicting the system robot_dynamics as well as human input into the future These predictions are complicated by the fact that the human is interacting with the robot causing the prediction method itself to have an effect on future human inputs We investigate and develop different prediction schemes including fixed and variable horizon MPCs and human input estimators of different orders Through a search-and-rescue-inspired human_operator study we arrive at the conclusion that the simplest prediction methods outperform the more complex ones i e in this particular case less is indeed more
Enhanced Color-Theory-Based Dynamic Localization in mobile_wireless_sensor_networks
There are few localization_schemes targeted at mobile_wireless_sensor_networks This paper proposed an enhanced color-theory-based dynamic localization E-CDL which is based on the CDL algorithm Shee 2005 However the location accuracy of this algorithm depends on the accuracy of the average hop distance derivation Therefore the authors present two novel schemes to estimate the average hop distance The authors analyzed the behavior of sensor_nodes communication and computed the expected value of the average hop distance which is 7r 9 where r is the radio range In addition since CDL is based on the DV-hop scheme the derived shortest_path length is usually larger than the corresponding Euclidean distance With this observation the derived shortest_path length can be adjusted by the ratio of the Euclidean distance and the shortest_path distance to further enhance the location accuracy Finally in mobile_wireless_sensor_networks sensor_nodes may become isolated By employing mobile anchor_nodes the isolation problem can be relieved and hence the location accuracy can be improved Simulation results have shown that the location accuracy of E-CDL is 50 -55 better than that of CDL and 75 -80 better than that of MCL monte_carlo_localization Lingxuan and David 2004 In addition the authors have implemented and verified our algorithm on the MICAz Mote developer s kit
Biometric binary string generation with detection_rate optimized bit_allocation
Extracting binary strings from real-valued templates has been a fundamental issue in many biometric_template_protection systems In this paper we present an optimal_bit_allocation method OBA By means of it a binary string at a pre-defined length with maximized overall detection_rate is generated Experiments with the binary strings and a hamming_distance classifier on FRGC and feret_databases show promising performance in terms of FAR and FRR
Dynamic identification of a 6 dof robot without joint position data
Off-line robot dynamic identification methods are mostly based on the use of the inverse dynamic model which is linear with respect to the dynamic parameters This model is calculated with torque and position sampled data while the robot is tracking reference trajectories that excite the system dynamics This allows using linear least-squares techniques to estimate the parameters This method requires the joint force torque and position measurements and the estimate of the joint velocity and acceleration through the bandpass filtering of the joint position at high sampling rates A new method called DIDIM Direct and Inverse Dynamic Identification Models has been proposed and validated on a 2 degree-of-freedom robot 1 DIDIM method requires only the joint force torque measurement It is based on a closed-loop simulation of the robot using the direct dynamic model the same structure of the control law and the same reference trajectory for both the actual and the simulated robot The optimal parameters minimize the 2-norm of the error between the actual force torque and the simulated force torque A validation experiment on a 6 dof Staubli TX40 robot shows that DIDIM method is very efficient on industrial_robots
Bit-Stream Switching in Multiple Bit-Rate video_streaming using wyner-ziv_coding
It has been commonly recognized that multiple bit-rate MBR encoding provides a concise method for video_streaming over bandwidth-fluctuant networks The key problem of the MBR technique lies in how to seamlessly switch one bit-stream to another one To tackle this problem we propose a bit-stream switching framework based on the wyner-ziv_coding Within the propose framework the multiple bit-streams can be individually encoded without data_exchange which also supports the random switching at any desired frame without affecting the original coding_efficiency of the regular bit-stream In particular two different implementation schemes under the same framework are presented Different from the traditional switching schemes the proposed method can use the same switching frame for the switching from any other bit-stream to the current one which means less storage and less encoding efforts Simulation results and comparison between the proposed method and the traditional switching method in H 264 are also presented
An architecture for linking medical decision-support applications to clinical databases and its evaluation
We describe and evaluate a framework the medical_database Adaptor MEIDA for linking knowledge-based medical decision-support systems MDSSs to multiple clinical databases using standard medical schemata and vocabularies Our solution involves a set of tools for embedding standard terms and units within knowledge_bases KBs of MDSSs a set of methods and tools for mapping the local database DB schema and the terms and units relevant to the KB of the MDSS into standardized schema terms and units using three heuristics choice of a vocabulary choice of a key term and choice of a measurement unit and a set of tools which at runtime automatically map standard term queries originating from the KB to queries formulated using the local DB s schema terms and units The methodology was successfully evaluated by mapping three KBs to three DBs Using a unit-domain matching heuristic reduced the number of term-mapping candidates by a mean of 71 even after other heuristics were used Runtime access of 10 000 records required one second We conclude that mapping MDSSs to different local clinical DBs using the three-phase methodology and several term-mapping heuristics is both feasible and efficient
Animation Metaphors for Object-Oriented Concepts
Program visualization and animation has traditionally been done at the level of the programming_language and its implementation in a computer However novices do not know these concepts and visualizations that build upon programming_language implementation may easily fail in helping novices to learn programming concepts Metaphor on the contrary involves the presentation of a new idea in terms of a more familiar one and can facilitate active_learning This paper applies a metaphor approach to object-oriented_programming by presenting new metaphors for such concepts as class object object instantiation method invocation parameter passing object reference and garbage collection The use of these metaphors in introductory_programming_education is also discussed
Performance of recovery_time improvement algorithms for software RAIDs
A software RAID is a RAID implemented purely in software running on a host computer One problem with software RAIDs is that they do not have access to special hardware such as NVRAM Thus software RAIDs may need to check every parity group of an array for consistency following a host crash or power failure This process of checking parity groups is called recovery and results in long delays when the software RAID is restarted The authors review two algorithms to reduce this recovery_time for software RAIDs the PGS bitmap algorithm and the list algorithm They compare the performance of these two algorithms using trace-driven simulations Their results show that the PGS bitmap algorithm can reduce recovery_time by a factor of 12 with a response time penalty of less than 1 or by a factor of 50 with a response time penalty of less than 2 and a memory requirement of around 9 Kbytes The list algorithm can reduce recovery_time by a factor of 50 but cannot achieve a response time penalty of less than 16
Independent gate SRAM based on asymmetric gate to source drain overlap-underlap device FinFET
The read-write ability of sram_cells is one of the major concern in nanometer regime This paper analyzes the stability and performance of asymmetric FinFET based different schematic of 6T sram_cells The proposed structure exploits asymmetrical behavior of current to improve read-write stability of SRAM By exploiting the asymmetricity in proposed structure contradiction between read and write noise margin RNM and WNM is relaxed The overall improvements in static read and write noise margins for proposed asymmetric FinFET based independent gate SRAM IGSRAM are 28 71 and 31 respectively
Distributed scalable and static parallel arc consistency algorithms on private memory machines
Several arc consistency algorithms for sequential and parallel_processing computers are reviewed Three distributed parallel arc consistency algorithms-DSPAC-1 DSPAC-2 and DSPAC-3-are introduced and compared with existing algorithms Through actual machine experimentation the time required for the DSPAC algorithms was measured and compared with that for existing sequential algorithms Results indicate that the parallel arc consistency algorithms are very effective and that scalability can be efficiently maintained
Provisioning on-chip_networks under Buffered RC Interconnect Delay Variations
A network-on-chip NoC replaces on-chip communication implemented by point-to-point interconnects in a multi-core environment by a set of shared interconnects connected through programmable crosspoints Since an NoC may provide a number of paths between a given source and destination manufacturing or runtime faults on one interconnect does not necessarily render the chip useless It is partly because of this fault_tolerance that NoCs have emerged as a viable alternative for implementing communication between functional units of a chip in the nanometer regime where high defect rates are prevalent In this paper the authors quantify the fault_tolerance offered by an NoC against process_variations Specifically the authors develop an analytical model for the probability of failure in buffered global NoC links due to interconnect dishing and effective channel length variation Using the developed probability model the authors study the impact of link failure on the number of cycles required to establish communications in NoC applications
Accurate Distributed Range-Based Positioning Algorithm for wireless_sensor_networks
Localization of sensor_nodes is a fundamental and important problem in wireless_sensor_networks In this correspondence a recursive distributed positioning algorithm is devised with the use of range_measurements Computer simulations are included to contrast the performance of the proposed approach with the conventional semi-definite relaxation positioning method as well as Crameacuter-Rao lower bound
Prospective multi-centre voxel_based_morphometry study employing scanner specific segmentations procedure development using CaliBrain structural MRI data
Background R N Structural Magnetic Resonance Imaging sMRI of the brain is employed in the assessment of a wide range of neuropsychiatric disorders In order to improve statistical power in such studies it is desirable to pool scanning resources from multiple centres The CaliBrain project was designed to provide for an assessment of scanner differences at three centres in Scotland and to assess the practicality of pooling scans from multiple-centres
Improving the scalability of cloud-based resilient database servers
Many rely now on public cloud infrastructure-as-a-service for database servers mainly by pushing the limits of existing pooling and replication software to operate large shared-nothing virtual server clusters Yet it is unclear whether this is still the best architectural choice namely when cloud infrastructure provides seamless virtual shared storage and bills clients on actual disk usage This paper addresses this challenge with Resilient Asynchronous Commit RAsC an improvement to awell-known shared-nothing design based on the assumption that a much larger number of servers is required for scale than for resilience Then we compare this proposal to other database server architectures using an analytical model focused on peak throughput and conclude that it provides the best performance cost trade-off while at the same time addressing a wide range of fault scenarios
A neural_network-based image_processing system_for detection of vandal acts in unmanned railway environments
Lately the interest in advanced video-based surveillance_applications has been increasing This is especially true in the field of urban railway transport where video-based surveillance can be exploited to face many relevant security aspects e g vandalism overcrowding abandoned object_detection etc This paper aims at investigating an open problem in the implementation of video-based surveillance_systems for transport applications i e the implementation of reliable image_understanding modules in order to recognize dangerous situations with reduced false alarm and misdetection_rates We considered the use of a neural_network-based classifier for detecting vandal behavior in metro stations The achieved results show that the classifier achieves very good performance even in the presence of high scene complexity
Recursive binary dilation and erosion using digital line structuring_elements in arbitrary orientations
Performing morphological_operations such as dilation and erosion of binary images using very long line structuring_elements is computationally expensive when performed brute-force following definitions We present two-pass algorithms that run at constant time for obtaining binary dilations and erosions with all possible length line structuring_elements simultaneously The algorithms run at constant time for any orientation of the line structuring_element Another contribution of this paper is the use of the concept of orientation error between a continuous line and its discrete counterpart The orientation error is used in determining the minimum length of the basic digital line structuring_element used in obtaining what we call dilation and erosion transforms The transforms are then thresholded by the length of the desired structuring_element to obtain the dilation and erosion results The algorithms require only one maximum operation for erosion transform and only one minimum operation for dilation transform and one thresholding step and one translation step per result pixel We tested the algorithms on Sun Sparc Station 10 on a set of 240 spl times 250 salt and pepper_noise images with probability of a pixel being a 1-pixel set to 0 25 for orientations of the normals of the structuring_elements in the range spl pi 2 3 spl pi 2 and lengths in pixels in the range 5 145 We achieved a speed up of about 50 and for special orientations spl theta spl isin spl pi 2 3 spl pi 4 spl pi 5 spl pi 4 3 spl pi 2 a speed up of about 100 when the structuring_elements had lengths of 145 pixels over the brute-force methods in these experiments We compared the results of our dilation algorithm with those of the algorithm discussed by Soille et al see IEEE Trans Pattern Anal Machine Intell vol 18 p 562-67 1996 and showed that for binary dilation and erosion since it is just the dilation of the background with the reflected structuring_element our algorithm performed better and achieved a speed up of about four when dilation or erosion transform alone is obtained
Using assignment examples to infer weights for ELECTRE TRI method Some experimental results
Given a finite set of alternatives A the sorting or assignment_problem consists in the assignment of each alternative to one of the pre-defined categories In this paper we are interested in multiple criteria sorting problems and more precisely in the existing method ELECTRE TRI This method requires the elicitation of preferential parameters weights thresholds category limits in order to construct a preference model which the decision maker DM accepts as a working hypothesis in the decision aid study A direct elicitation of these parameters requiring a high cognitive effort from the DM V Mosseau R Slowinski Journal of Global Optimization 12 2 1998 174 proposed an interactive aggregation disaggregation approach that infers ELECTRE TRI parameters indirectly from holistic information i e assignment examples In this approach the determination of ELECTRE TRI parameters that best restore the assignment examples is formulated through a nonlinear optimization program R N R N In this paper we consider the subproblem of the determination of the weights only the thresholds and category limits being fixed This subproblem leads to solve a linear program rather than nonlinear in the global inference model numerical_experiments were conducted so as to check the behaviour of this disaggregation tool Results showed that this tool is able to infer weights that restores in a stable way the assignment examples and that it is able to identify inconsistencies in the assignment examples
A 250 mV 8 kb 40 nm Ultra-low_power 9T Supply Feedback SRAM SF-SRAM
Low voltage operation of digital circuits continues to be an attractive option for aggressive power reduction As standard SRAM bitcells are limited to operation in the strong-inversion regimes due to process_variations and local mismatch the development of specially designed SRAMs for low voltage operation has become popular in recent years In this paper we present a novel 9T bitcell implementing a Supply Feedback concept to internally weaken the pull-up current during write cycles and thus enable low-voltage write_operations As opposed to the majority of existing solutions this is achieved without the need for additional peripheral circuits and techniques The proposed bitcell is fully functional under global and local variations at voltages from 250 mV to 1 1 V In addition the proposed cell presents a low-leakage state reducing power up to 60 as compared to an identically supplied 8T bitcell An 8 kbit SF-SRAM array was implemented and fabricated in a low-power 40 nm process showing full functionality and ultra-low_power
Map-Aided Evidential Grids for Driving scene_understanding
Evidential grids have recently been shown to have interesting properties for mobile object perception Possessing only partial information is a frequent situation when driving in complex urban areas and by making use of the Dempster-Shafer framework evidential grids are able to handle partial information efficiently This article deals with a lidar perception scheme that is enhanced by geo-referenced maps used as an additional source of information in a multi-grid fusion framework The paper looks at the key stages of such a data_fusion_process and presents an adaptation of the conjunctive combination rule for refining the analysis of conflicting information This method relies on temporal accumulation to distinguish between stationary and moving_objects and applies contextual discounting for modeling information obsolescence As a result the method is able to better characterize the state of the occupied cells by differentiating moving_objects parked cars urban infrastructure and buildings Another advantage of this approach is its ability to separate the drivable from the non-drivable free space Experiments carried out in real_traffic conditions with a specially equipped car illustrate the performance of this approach
Interferential Packet Detection Scheme for a Solution to Overlapping BSS Issues in IEEE 802 11 WLANs
In this manuscript an interferential packet detection scheme in IEEE 802 11 WLANs is proposed If another Basic Service Set BSS is overlapping domestic BSS some Stations STAs may suffer from interference from a hidden_terminal in overlapping BSS OBSS One of the best ways to avoid this undesirable situation is channel_switching after detecting OBSS However there are some difficulties to recognize existence of OBSS One difficulty is that STAs in domestic BSS can t receive frames from OBSS correctly and can t check BSSID of frames if traffic in domestic BSS is heavy and if transmission rates of frames from OBSS are higher Another difficulty is that if the cell radius of domestic BSS is smaller than that of OBSS some STAs in OBSS may transmit frames asynchronously and interfere with transmissions in domestic BSS If interference causes frame error domestic STA can t distinguish interference from degradation of channel condition This paper proposes a method whereby STAs can detect interferential packet even while STAs receive frames from domestic BSS If STAs detect interference_channel_switching is performed dynamically The probability of detecting interferential packets is evaluated by computer simulation and the results confirm the effectiveness of the proposed method
Optimal error_estimates for finite element discretization of elliptic optimal_control_problems with finitely many pointwise state constraints
In this paper we consider a model elliptic optimal_control_problem with finitely many state constraints in two and three dimensions Such problems are challenging due to low regularity of the adjoint variable For the discretization of the problem we consider continuous linear elements on quasi-uniform and graded meshes separately Our main result establishes optimal a priori error_estimates for the state adjoint and the Lagrange multiplier on the two types of meshes In particular in three dimensions the optimal second order convergence rate for all three variables is possible only on properly refined meshes numerical_examples at the end of the paper support our theoretical_results
Taxonomy of trust Categorizing P2P reputation systems
The field of peer-to-peer reputation systems has exploded in the last few years Our goal is to organize existing ideas and work to facilitate system design We present a taxonomy of reputation system components their properties and discuss how user behavior and technical constraints can conflict In our discussion we describe research that exemplifies compromises made to deliver a useable implementable system
Performance of a 60-GHz DCM-OFDM and BPSK-Impulse Ultra-Wideband System with Radio-Over-Fiber and Wireless Transmission Employing a Directly-Modulated VCSEL
The performance of radio-over-fiber optical_transmission employing vertical-cavity surface-emitting lasers VCSELs and further wireless transmission of the two major ultra-wideband UWB implementations is reported when operating in the 60-GHz radio band Performance is evaluated at 1 44 Gbit s bitrate The two UWB implementations considered employ dual-carrier modulation orthogonal frequency-division multiplexing DCM-OFDM and binary phase-shift keying impulse_radio BPSK-IR modulation respectively optical_transmission distances up to 40 km in standard single-mode fiber and up to 500 m in bend-insensitive single-mode fiber with wireless transmission up to 5 m in both cases is demonstrated with no penalty A simulation analysis has also been performed in order to investigate the operational limits The analysis results are in excellent agreement with the experimental work and indicate good tolerance to chromatic_dispersion due to the chirp characteristics of electro-optical conversion when a directly-modulated VCSEL is employed The performance comparison indicates that BPSK-IR UWB exhibits better tolerance to optical_transmission impairments requiring lower received optical power than its DCM-OFDM UWB counterpart when operating in the 60-GHz band
DPLL bit synchronizer with rapid acquisition using adaptive_kalman_filtering techniques
A second-order DPLL with time-varying loop gains is applied to the symbol synchronization of burst mode data signals An algorithm to control the DPLL loop gains is derived from adaptive_kalman_filtering theory Simulation results for the variable gain DPLL compared to a fixed gain DPLL demonstrate the improved acquisition performance
A 65 nm CMOS Quad-Band SAW-Less Receiver SoC for GSM GPRS EDGE
A quad-band 2 5G receiver is designed to replace the front-end SAW filters with on-chip bandpass filters and to integrate the LNA matching components as well as the RF baluns The receiver achieves a typical sensitivity of -110 dBm or better while saving a considerable amount of BOM Utilizing an arrangement of four baseband capacitors and MOS switches driven by 4-phase 25 duty-cycle clocks high-Q BPF s are realized to attenuate the 0 dBm out-of-band blocker The 65 nm CMOS SAW-less receiver integrated as a part of a 2 5G SoC draws 55 mA from the battery and measures an out-of-band 1 dB-compression of greater than 2 dBm Measured as a stand-alone as well as the baseband running in call mode in the platform level the receiver passes the 3GPP specifications with margin
Automated evaluation of HER-2 neu immunohistochemical expression in breast cancer using digital microscopy
HER-2 neu HER2 has been shown to be a valuable biomarker for breast cancer However inter-observer variability has been reported in the evaluation of HER2 with immunohistochemistry It has been suggested that automated computer-based evaluation can provide a consistent and objective measure of HER2 expression In this manuscript we present an automated method for the quantitative assessment of HER2 using digital microscopy The method employs imaging_algorithms on whole slide images of tissue specimens for the extraction of two features describing HER2 membrane staining namely membrane staining completeness and membrane staining intensity A classifier was trained to merge the extracted features into an overall slide assessment score Preliminary results showed good agreement with the provided truth The developed automated method has the potential to be used as a computer aid for the immunohistochemical evaluation of HER2 expression with the objective of increasing observer reproducibility
Adding expressiveness to musical messages
A system to add expressiveness to musical messages has been developed starting from the results of acoustic and perceptual analyses The system allows to obtain different performances by modifying the acoustic parameters of a given neutral performance The modification of the input performance is performed by a model that uses the hierarchical segmentation of the musical organization For every hierarchical level opportune curves are applied to the principal acoustic parameters Level s self-similarity is the main criteria to construct the curves The modular structure of the system defines an open architecture where the rendering steps can be realized both with synthesis and post-processing techniques Different synthesis techniques like FM physical models or wavetable have been explored
Observations on using empirical studies on developing a knowledge-based software_engineering tool
There exist a wide variety of techniques for performing empirical studies which researchers in human-computer_interaction have adapted from fields of cognitive psychology sociology and anthropology An analysis of several of these techniques is presented through an approach that balances empirical study with tool development The analysis is based on and illustrated with a several-year experience of consulting in a scientific software environment and in building an evaluating a prototype knowledge-based tool to capture aspects of that experience Guidelines for applying specific techniques and cautions about potential pitfalls are discussed Many additional examples of using the techniques are cited from the literature
Fire Detection by Microwave Radiometric Sensors Modeling a Scenario in the Presence of Obstacles
This paper deals with the problem of fire detection in the presence of obstacles that are nontransparent to visible or infrared wavelengths Exploiting the obstacle penetration capability of microwaves a solution based on passive microwave radiometry has been proposed To investigate such a solution a theoretical model of the scene sensed by a microwave radiometer is developed accounting for the presence of both fire spot and wall-like obstacles By reversing the model s equations it is possible to directly relate the obstacle emissivity reflectivity and transmissivity to the antenna noise temperatures measured in several conditions These temperatures have been sensed with a portable low-cost instrument The selected 12 65-GHz operation frequency features good wall penetration capability to be balanced with a reasonable antenna size In order to verify the aforementioned model several fire experiments have been carried out resulting in an overall good agreement between measurements and developed theory In particular a 2-cm-thick plasterboard wall typically used for indoor building construction shows a transmissivity equal to 0 86 and can easily be penetrated by a microwave radiometer in the X-band
Efficient evaluation of queries with mining predicates
Modern relational_database_systems are beginning to support ad-hoc queries on data_mining models In this paper we explore novel techniques for optimizing queries that apply mining models to relational_data For such queries we use the internal structure of the mining model to automatically derive traditional database predicates We present algorithms for deriving such predicates for some popular discrete mining models decision_trees naive_bayes and clustering Our experiments on a microsoft_sql_server 2000 demonstrate that these derived predicates can significantly reduce the cost of evaluating such queries
stochastic_processes via the pathway model
After collecting data from observations or experiments the next step is to analyze the data to build an appropriate mathematical or stochastic_model to describe the data so that further studies can be done with the help of the model In this article the input-output type mechanism is considered first where reaction diffusion reaction-diffusion and production-destruction type physical situations can fit in Then techniques are described to produce thicker or thinner tails power law behavior in stochastic_models Then the pathway idea is described where one can switch to different functional forms of the probability_density_function through a parameter called the pathway parameter The paper is a continuation of related solar neutrino research published previously in this journal
Predictive Metamorphic Control
Model Predictive Control MPC has become widely accepted in industry The reason for its success are manifold including easy implementation ability to handle constraints capacity to deal with nonlinearities etc However the method does have drawbacks including tuning difficulties In this paper we propose an embellishment to the basic MPC strategy by incorporating a tuning parameter such that one can move continuously from an existing controller to a new MPC strategy The continuous change of this tuning parameter leads to a continuously varying stabilizing control law Since the proposed strategy allows one to slowly move from an existing control law to a new and better one we term the strategy Predictive Metamorphic Control For the case of an infinite horizon problem without constraints and for the general case with state and input constraints stability results are established The merits of the proposed method are illustrated by examples
Efficient network flow based min-cut balanced partitioning
We consider the problem of bipartitioning a circuit into two balanced components that minimizes the number of crossing nets Previously the Kernighan and Lin type K L heuristics the simulated_annealing approach and the spectral method were given to solve the problem However network flow techniques were overlooked as a viable approach to min-cut balanced bipartition to due its high complexity In this paper we propose a balanced bipartition heuristic based on repeated max-flow min-cut techniques and give an efficient implementation that has the same asymptotic time complexity as that of one max-flow computation We implemented our heuristic algorithm in a package called FBB The experimental results demonstrate that FBB outperforms the K L heuristics and the spectral method in terms of the number of crossing nets and the efficient implementation makes it possible to partition large circuit instances with reasonable runtime For example the average elapsed time for bipartitioning a circuit S35932 of almost 20K gates is less than 20 minutes
Reconstruction of polynomial systems from noisy time-series measurements using genetic_programming
The problem of functional reconstruction of a polynomial system_from its noisy time-series measurement is addressed in this paper The reconstruction requires the determination of the embedding dimension and the unknown polynomial structure The authors propose the use of genetic_programming GP to find the exact functional form and embedding dimension of an unknown polynomial system_from its time-series measurement Using functional operators of addition multiplication and time_delay they use GP to reconstruct the exact polynomial system and its embedding dimension The proposed GP approach uses an improved least-squares ILS method to determine the parameters of a polynomial system The ILS method is based on the orthogonal Euclidean distance to obtain an accurate parameter estimate when the series is corrupted by measurement_noise Simulations show that the proposed ILS-GP method can successfully reconstruct a polynomial system_from its noisy time-series measurements
grid_service for Environmental Data Retrieval and Disasters Detection Based on Satellite image_analysis
Considering that one of today s biggest global concerns is related to the climate change and its imminent undesired effects we present the approach of creating and offering a public Web service to provide real-time access to environmental data and information One of service s direct usages is natural disasters detection but it could be further used for developing complex statistics and prediction generators or for other environment related applications The data is extracted from a satellite imagery repository implemented on a Grid infrastructure For testing the capabilities of the service for different type of users a visualization and interaction web_application has been developed The service is integrated in the MedioGRID system
An Evaluation Framework for energy_aware Buildings using statistical_model_checking
cyber-physical_systems are to be found in numerous applications throughout society The principal barrier to develop trustworthy cyber-physical_systems is the lack of expressive modelling and specification formalisms supported by efficient tools and methodologies To overcome this barrier we extend in this paper the modelling formalism of the tool UPPAAL-SMC to stochastic hybrid_automata thus providing the expressive power required for modelling complex cyber-physical_systems The application of statistical_model_checking provides a highly scalable technique for analyzing performance properties of this formalisms
ML-Flex a flexible toolbox for performing classification analyses in parallel
Motivated by a need to classify high-dimensional heterogeneous data from the bioinformatics domain we developed ML-Flex a machine-learning_toolbox that enables users to perform two-class and multi-class_classification analyses in a systematic yet flexible manner ML-Flex was written in Java but is capable of interfacing with third-party packages written in other programming_languages It can handle multiple input-data formats and supports a variety of customizations MLFlex provides implementations of various validation strategies which can be executed in parallel across multiple computing cores processors and nodes Additionally ML-Flex supports aggregating evidence across multiple algorithms and data sets via ensemble_learning This open-source software package is freely available from http mlflex sourceforge net
Pacemaker interference and low-frequency electric induction in humans by external fields and electrodes
The possibility of interference by low-frequency external electric fields with cardiac pacemakers is a matter of practical concern For pragmatic reasons experimental investigations into such interference have used contact electrode current sources However the applicability to the external electric field problem remains unclear The recent development of anatomically based electromagnetic models of the human body together with progress in computational_electromagnetics enable the use of numerical_modeling to quantify the relationship between external field and contact electrode excitation This paper presents a comparison between the computed fields induced in a 3 6-mm-resolution conductivity model of the human body by an external electric field and by several electrode source configurations involving the feet and either the head or shoulders The application to cardiac pacemaker interference is also indicated
A Structurally Stable Globally Adaptive Internal Model Regulator for MIMO linear_systems
The problem of compensating an uncertain disturbance and or tracking some reference signals for a general linear MIMO system is studied in this work using the robust regulation theory frame The disturbances are assumed to be composed by a known number of distinct sinusoidal_signals with unknown phases amplitude and frequencies Under suitable assumptions an exponentially convergent estimator of the unknown disturbance parameters is proposed and introduced into the classical robust regulator design to obtain an adaptive_controller This controller guarantees that the closed-loop robust regulation is attained in some neighborhood of the nominal values of the parameters of system A simulated example shows the validity of the proposed approach
Developing discriminate model and comparative analysis of differentially expressed genes and pathways for bloodstream samples of diabetes mellitus type 2
Background R N Diabetes mellitus of type 2 T2D also known as noninsulin-dependent diabetes mellitus NIDDM or adult-onset diabetes is a common disease It is estimated that more than 300 million people worldwide suffer from T2D In this study we investigated the T2D pre-diabetic and healthy human no diabetes bloodstream samples using genomic genealogical and phonemic information We identified differentially expressed genes and pathways The study has provided deeper insights into the development of T2D and provided useful information for further effective prevention and treatment of the disease
An autonomous sewer robots navigation based on stereo_camera information
In this paper we propose a method for autonomous sewer robots to navigate through a sewer pipe system based on stereo_camera information In this method local_features such as manholes and pipe joints are extracting as a feature pixels in the region of interest ROI of left image Then an accurate and fast stereo_matching measure named linear computation is implemented in this ROI image to compute the distance between the robots and local_features Finally the distance data can be used for navigation map in sewer pipe system The experimental results show that our method can provide sufficient information for autonomous sewer robots navigation
Introducing a geographic_information_system as computer tool to apply the problem-based_learning process in public buildings indoor routing
Abstract R N R N A geographic_information_system GIS is presented in this work with the aim of helping the application of problem-based_learning process to show the students how to adopt the appropriate decisions for the adaptation of architectural barriers to ensure the universal accessibility in public buildings The GIS developed here consists of three layers based on vector maps corresponding to buildings potential routes and architectural barriers Hyperlinks in the last layer allow access to some relevant information about each barrier such as type description and adaptation cost Several tests have been carried out to show the capability of the implemented GIS to locate indoor barriers determine suitable indoor routes by considering criteria such as paths lengths or the total cost of barrier elimination and update the information corresponding to each architectural barrier In addition the application of the proposed GIS has also been explored for indoor route guidance with promising results This investigation has been carried out with the aim of being combined with the problem-based_learning process 2010 Wiley Periodicals Inc Comput Appl Eng Educ 21 573 580 2013
A Practical Location-aided energy-aware_routing Method for UWB-based sensor_networks
In this paper a practical location-aided routing method for sensor_networks based on ultra-wideband UWB technique is proposed and evaluated This method makes use of the positioning function of UWB and takes into account the energy consumption in the network By modeling the property of energy consumption we find that energy and quality-of-service QOS issues are greatly influenced by the route selected Accordingly a new routing_algorithm is derived to search for energy-efficient routes that can support adequate qos_requirements The simulation results have proved the advantages of this routing_scheme
Waveband switching_networks with limited wavelength_conversion
We study reconfigurable multi-granular optical cross-connects MG-OXCs in waveband switching_networks with limited wavelength_conversion and propose a heuristic algorithm to minimize the number of used wavelength_converters while reducing the blocking_probability
An identity-based identification scheme based on discrete_logarithms modulo a composite number
We first describe a modification of Schnorr s identification scheme in which the modulus is composite instead of prime This modification has some similarity with Brickell-McCurky s one presented at the same conference Then by establishing a new set-up we derive the first identity-based identification scheme based on discrete_logarithms More precisely it is based on discrete_logarithm modulo a composite number a problem known to be harder than factorization problem This scheme has interesting and somewhat paradoxical features In particular any user can choose his own secret and provided the parameters have convenient sizes even the trusted center is unable to retrieve it from the public_key contrary to any identity-based scheme known until now
Control of Artificial pneumatic_muscle for Robot Application
pneumatic_muscle has many advantages such as elasticity high power and structural similarity to a living thing s muscle There has been many researches to control robot actuated by pneumatic_muscles but conventional theories are hard to apply on real_robot plants because of their assumptions and disregards of pneumatic_muscle s physical aspects like size of pneumatic_muscle and its controller Here the new method for saving space which is occupied by many controllers to operate robot actuated by pneumatic_muscles is proposed Actually there is easy way to control pneumatic_muscle using the commercial proportional pressure regulator but its size is not suitable to be embedded on stand alone robot So new method using the pressure switches of compact size and encoders is suggested This new method is tested on a robot link with ball joints actuated by four pneumatic_muscles
The role of EDM in information_management within SMEs
electronic_document management EDM is a new form of information_management EDM is described to have certain business values in organizations but no research has been found about EDM and Small and Medium sized Enterprises SME In this paper we present an ongoing investigation in two SMEs guided by the following research questions How are electronic_documents used in the SMEs and What are the business needs of the SMEs and how do they correspond with stated EDM business values The study was carried out as two qualitative case studies in two SMEs in the north of Sweden The results show that the business need for an SME corresponds with the business values of EDM Yet is management of electronic_document too dependent on individuals competence very complex when many systems are involved and the context where the document is created is not preserved There is also an emergent need for an organization-specific classification scheme to enable information_sharing between systems
Forensic acquisition and analysis of magnetic tapes
Recovering evidential data from magnetic tapes in a forensically sound manner is a difficult task There are many different tape technologies in existence today and an even greater number of archive formats used This paper discusses the issues and challenges involved in the forensic acquisition and analysis of magnetic tapes It identifies areas of slack space on tapes and discusses the challenges of low level acquisition of an entire length of tape It suggests a basic methodology for determining the contents of a tape acquiring tape files and preparing them for forensic_analysis
BIFURCATION CHAOS AND THEIR CONTROL IN A TIME-DELAY DIGITAL TANLOCK LOOP
This paper reports the detailed parameter space study of the nonlinear dynamical behaviors and their control in a time-delay digital tanlock loop TDTL At first we explore the nonlinear dynamics of the TDTL in parameter space and show that beyond a certain value of loop gain parameter the system manifests bifurcation and chaos Next we consider two variants of the delayed feedback_control DFC technique namely the time-delayed feedback_control TDFC technique and its modified version the extended time-delayed feedback_control ETDFC technique Stability analyses are carried out to find out the stable phase-locked zone of the system_for both the controlled cases We employ two-parameter bifurcation diagrams and the lyapunov_exponent spectrum to explore the dynamics of the system in the global parameter space We establish that the control techniques can extend the stable phase-locked region of operation by controlling the occurrence of bifurcation and chaos We also derive an estimate of the optimum parameter values for which the controlled system has the fastest convergence time even for a larger acquisition range The present study provides a necessary detailed parameter space study that will enable one to design an improved TDTL system
Contribution to the Determination of In Vivo Mechanical Characteristics of Human Skin by Indentation Test
This paper proposes a triphasic model of intact skin in vivo based on a general phenomenological thermohydromechanical and physicochemical THMPC approach of heterogeneous media The skin is seen here as a deforming stratified medium composed of four layers and made out of different fluid-saturated materials which contain also an ionic component All the layers are treated as linear isotropic_materials described by their own behaviour law The numerical simulations of in vivo indentation test performed on human skin are given The numerical_results correlate reasonably well with the typical observations of indented human skin The discussion shows the versatility of this approach to obtain a better understanding on the mechanical behaviour of human skin layers separately
transmit_power adaptation for multiuser ofdm_systems
In this paper we develop a transmit_power adaptation method that maximizes the total data rate of multiuser orthogonal_frequency_division_multiplexing ofdm_systems in a downlink transmission We generally formulate the data rate maximization problem by allowing that a subcarrier could be shared by multiple users The transmit_power adaptation scheme is derived by solving the maximization problem via two steps subcarrier assignment for users and power_allocation for subcarriers We have found that the data rate of a multiuser OFDM system is maximized when each subcarrier is assigned to only one user with the best channel gain for that subcarrier and the transmit_power is distributed over the subcarriers by the water-filling policy In order to reduce the computational complexity in calculating water-filling level in the proposed transmit_power adaptation method we also propose a simple method where users with the best channel gain for each subcarrier are selected and then the transmit_power is equally distributed among the subcarriers Results show that the total data rate for the proposed transmit_power adaptation methods significantly increases with the number of users owing to the multiuser_diversity effects and is greater than that for the conventional frequency-division multiple_access FDMA -like transmit_power adaptation schemes Furthermore we have found that the total data rate of the multiuser OFDM system with the proposed transmit_power adaptation methods becomes even higher than the capacity of the awgn_channel when the number of users is large enough
Fine grain associative feature reasoning in collaborative engineering
This paper explores the vast domain of systematic collaborative engineering with reference to product lifecycle management approach from the angle of feature-level collaboration among partners A new method of fine grain feature association modelling and reasoning is proposed The original contribution is on the explicit modelling and reasoning of collaborative feature relations within a dynamic context A case study has been carried out to illustrate the interweaving feature relations in collaborative oil rig space management and the effective application of such relations modelled in design solution optimisation
Multiple ant tracking with global foreground maximization and variable target proposal_distribution
Motion and behavior analysis of social insects such as ants requires tracking many ants over time This process is highly labor-intensive and tedious automatic_tracking is challenging as ants often interact with one another resulting in frequent occlusions that cause drifts in tracking In addition tracking many objects is computationally expensive In this paper we present a robust and efficient method for tracking multiple ants We first prevent drifts by maximizing the coverage of foreground pixels at at global scale Secondly we improve speed by reducing markov_chain length through dynamically changing the target proposal_distribution for perturbed ant selection Using a real dataset with ground truth we demonstrate that our algorithm was able to improve the accuracy by 15 resulting in 98 tracking_accuracy and the speed by 76
A Framework for Discrete Modeling of Juxtacrine Signaling Systems
Juxtacrine signaling is intercellular communication in which the receptor of the signal typically a protein as well as the ligand also typically a protein responsible for the activation of the receptor are anchored in the plasma membranes so that in this type of signaling the activation of the receptor depends on direct contact between the membranes of the cells involved Juxtacrine signaling is present in many important cellular events of several organisms especially in the development process We propose a generic formal_model a modeling framework for juxtacrine signaling systems that is a class of dynamic discrete_systems It possesses desirable characteristics in a good modeling framework such as a structural similarity with biological models b capacity of operating in different scales of time and c capacity of explicitly treating both the events and molecular elements that occur in the membrane and those that occur in the intracellular environment and are involved in the juxtacrine signaling process We implemented this framework and used to develop a new discrete model for the neurogenic network and its participation in neuroblast segregation
DIY interface for enhanced service customization of remote IoT devices a CoAP based prototype
DIY vision for the design of a smart and customizable world in the form of IoT demands the involvement of general public in its development process General public lacks the technical depths for programming state-of-the-art prototyping and development kits Latest IoT kits for example Intel Edison are revolutionizing the DIY paradigm for IoT and more than ever a DIY intuitive programming interface is required to enable masses to interact with and customize the behavior of remote IoT devices on the Internet This paper presents the novel implementation of such a system enabling general public to customize the behavior of remote IoT devices through a visual interface The interface enables the visualization of the resources exposed by a remote CoAP device in the form of graphical virtual_objects The VOs are used to create service design through simple operations like drag-and-drop and properties settings The design is maintained as an XML document thus being easily distributable and recognizable CoAP proxy acts as an operation client for the remote device and also provides communication link between the designer and the device The paper presents the architecture detailed design and prototype implementation of the system using state-of-the-art technologies
The Application and Research of ontology_construction Technology
In the field of search the application of ontology is an important research topic Introduction of ontology_technology in the retrieval system with massive data can make the searching results more comprehensive However now days the ontology is constructed by domain_experts and there are a lot of shortcomings such as complex process long time for the project and difficulty to update Thereby in this paper a method of semiautomaticly building ontology is proposed after synthetically analyzing a variety of methods and techniques about it The building process which is based on user_interests mines not only the concepts but also the potential relationships between concepts from the texts by the method of concepts clustering On the basis of such research an unique patent information_retrieval system based on ontology has been completed
intelligent_systems in accounting finance and management ISI journal and proceeding citations and research issues from most-cited papers
This paper analyses the citations from intelligent_systems in Accounting Finance and Management that have occurred in ISI s Web of Knowledge in February 2010 I found roughly 1000 citations to the journal under 10 different journal name abbreviations with roughly 25p of the citations occurring during 2008 2009 associated with 27 of the more frequently cited papers Using that citation data the H-index and the 40 42 with ties most-cited papers are presented I found that ISI s new proceedings data appear to have a different citation pattern than ISI s journal citation data resulting in citations to more sources but fewer citations per source I also examine the research methodologies and applications of the most-cited papers in an attempt to determine what areas have been cited most and where there are potential gaps in the research Copyright 2010 John Wiley Sons Ltd
Anomalous Network Packet Detection Using data_stream_mining
In recent years significant research has been devoted to the development of intrusion_detection_systems IDS able to detect anomalous computer_network_traffic indicative of malicious activity While signature-based IDS have proven effective in discovering known attacks anomaly-based IDS hold the even greater promise of being able to automatically detect previously undocumented threats Traditional IDS are generally trained in batch mode and therefore cannot adapt to evolving network data_streams in real time To resolve this limitation data_stream_mining techniques can be utilized to create a new type of IDS able to dynamically model a stream of network_traffic In this paper we present two methods for anomalous network packet detection based on the data_stream_mining paradigm The first of these is an adapted version of the DenStream algorithm for stream clustering specifically tailored to evaluate network_traffic In this algorithm individual packets are treated as points and are flagged as normal or abnormal based on their belonging to either normal or outlier clusters The second algorithm utilizes a histogram to create a model of the evolving network_traffic to which incoming traffic can be compared using pearson_correlation Both of these algorithms were tested using the first week of data from the DARPA 99 dataset with Generic HTTP Shell-code and Polymorphic attacks inserted We were able to achieve reasonably high detection_rates with moderately low false positive percentages for different types of attacks though detection_rates varied between the two algorithms Overall the histogram-based detection_algorithm achieved slightly superior results but required more parameters than the clustering-based algorithm As a result of its fewer parameter requirements the clustering_approach can be more easily generalized to different types of network_traffic streams
machine_learning in automated text_categorization
The automated categorization or classification of texts into predefined categories has witnessed a booming interest in the last 10 years due to the increased availability of documents in digital form and the ensuing need to organize them In the research community the dominant approach to this problem is based on machine_learning_techniques a general inductive process automatically builds a classifier by learning from a set of preclassified documents the characteristics of the categories The advantages of this approach over the knowledge_engineering approach consisting in the manual definition of a classifier by domain_experts are a very good effectiveness considerable savings in terms of expert labor power and straightforward portability to different domains This survey discusses the main approaches to text_categorization that fall within the machine_learning paradigm We will discuss in detail issues pertaining to three different problems namely document_representation classifier construction and classifier evaluation
Intelligent energy management agent for a parallel hybrid vehicle-part II torque distribution charge sustenance strategies and performance results
This paper represents the second part of a two-part paper on development of an intelligent energy management agent IEMA for parallel hybrid vehicles In this part energy management strategies for the torque distribution and charge sustenance tasks are established and implemented Driving situation_awareness-based fuzzy rule_bases are developed to make intelligent decisions on the power split function A charge sustenance strategy is developed in parallel to maintain adequate reserves of energy in the storage device for supporting an extended range of driving Simulation study is conducted for the proposed IEMA and performance results are analyzed to evaluate its viability as a possible solution to and an extendable framework for energy management for parallel hybrid electric vehicles
Evolution of Adaptive Synapses Robots with Fast Adaptive Behavior in New Environments
This paper is concerned with adaptation capabilities of evolved neural controllers We propose to evolve mechanisms for parameter self-organization instead of evolving the parameters themselves The method consists of encoding a set of local adaptation rules that synapses follow while the robot freely moves in the environment In the experiments presented here the performance of the robot is measured in environments that are different in significant ways from those used during evolution The results show that evolutionary adaptive_controllers solve the task much faster and better than evolutionary standard fixed-weight controllers that the method scales up well to large architectures and that evolutionary adaptive_controllers can adapt to environmental changes that involve new sensory characteristics including transfer from simulation to reality and across different robotic_platforms and new spatial relationships
Set-valued cooperative_games with fuzzy payoffs The fuzzy assignment game
In this paper we study cooperative_games with fuzzy payoffs The main advantage of the approach presented is the incorporation into the analysis of the problem of ambiguity inherent in many real-world collective decision situations We propose extensions of core concepts which maintain the fuzzy nature of allocations and lead to a more satisfactory study of the problem within the fuzzy context Finally we illustrate the extended core concepts and the approach to obtain the corresponding allocations through the analysis of assignment games with uncertain profits
